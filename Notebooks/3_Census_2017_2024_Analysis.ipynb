{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af953d-4fd5-4828-bc92-bb1799d6acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "EXCEL_PATH = r\"\\assessment_of_wells_chile\\data\\DGA\\DGA_dataset_analysis_output\\DGA_Data_Clean_With_Spatial_Joins.xlsx\"\n",
    "OUTPUT_FOLDER = r\"\\assessment_of_wells_chile\\data\\Census\\Census_Analysis_Output\"\n",
    "GDB_PATH = r\"\\assessment_of_wells_chile\\arcgis\\assessment_of_wells_chile\\Default.gdb\"\n",
    "LAYER_CENSO_2024 = \"Censo_24_Merge\"\n",
    "LAYER_CENSO_2017 = \"Microdatos_Censo_2017_Merge\"\n",
    "SHP_CUENCAS = r\"\\assessment_of_wells_chile\\data\\Basins\\Cuencas_BNA\\Cuencas_BNA.shp\"\n",
    "SHP_SHAC = r\"\\assessment_of_wells_chile\\data\\Aquifers\\INV_ACUIFEROS_SHAC_202302\\INV_ACUIFEROS_SHAC.shp\"\n",
    "\n",
    "TARGET_CRS = \"EPSG:4326\"\n",
    "SHAC_BUFFER_DISTANCE = 200\n",
    "\n",
    "REFERENCE_LAYERS = [\n",
    "    {\n",
    "        'path': GDB_PATH,\n",
    "        'layer_name': 'CHL_Municipalities',\n",
    "        'prefix': 'Muni',\n",
    "        'name_col': 'NAME',\n",
    "        'code_col': 'Code_Muni',\n",
    "        'native_crs': 'EPSG:3857',\n",
    "        'is_gdb': True\n",
    "    },\n",
    "    {\n",
    "        'path': GDB_PATH,\n",
    "        'layer_name': 'CHL_Regions',\n",
    "        'prefix': 'Region',\n",
    "        'name_col': 'NAME',\n",
    "        'code_col': 'ID',\n",
    "        'native_crs': 'EPSG:3857',\n",
    "        'is_gdb': True\n",
    "    },\n",
    "    {\n",
    "        'path': SHP_CUENCAS,\n",
    "        'layer_name': None,\n",
    "        'prefix': 'Cuenca',\n",
    "        'name_col': 'NOM_CUEN',\n",
    "        'code_col': 'COD_CUEN',\n",
    "        'native_crs': 'EPSG:32719',\n",
    "        'is_gdb': False\n",
    "    },\n",
    "    {\n",
    "        'path': SHP_SHAC,\n",
    "        'layer_name': None,\n",
    "        'prefix': 'SHAC',\n",
    "        'name_col': 'SHAC',\n",
    "        'code_col': 'COD_SHAC',\n",
    "        'native_crs': 'EPSG:32719',\n",
    "        'is_gdb': False\n",
    "    }\n",
    "]\n",
    "\n",
    "COL_AREA_17 = 'AREA'\n",
    "COL_AREA_24 = 'AREA_C'\n",
    "COL_PERS_17 = 'TOTAL_PERS'\n",
    "COL_PERS_24 = 'n_per'\n",
    "COL_VIVIENDAS_17 = 'VIV_OCUPA_'\n",
    "COL_VIVIENDAS_24 = 'n_vp_ocupada'\n",
    "COL_VIVIENDAS_TOTALES_17 = 'TOTAL_VIVI'\n",
    "COL_VIVIENDAS_TOTALES_24 = 'n_vp'\n",
    "\n",
    "WATER_SOURCES = {\n",
    "    'red_publica': {\n",
    "        'name': 'Red Publica',\n",
    "        'name_short': 'RedPublica',\n",
    "        'col_2017': 'VIV_AGUA_R',\n",
    "        'col_2024': 'n_fuente_agua_publica',\n",
    "        'description': 'Viviendas con origen del agua por red publica',\n",
    "        'priority': 1\n",
    "    },\n",
    "    'pozo': {\n",
    "        'name': 'Pozo o Noria',\n",
    "        'name_short': 'Pozo',\n",
    "        'col_2017': 'VIV_AGUA_P',\n",
    "        'col_2024': 'n_fuente_agua_pozo',\n",
    "        'description': 'Viviendas con origen del agua por pozo o noria',\n",
    "        'priority': 2\n",
    "    },\n",
    "    'camion': {\n",
    "        'name': 'Camion Aljibe',\n",
    "        'name_short': 'Camion',\n",
    "        'col_2017': 'VIV_AGUA_C',\n",
    "        'col_2024': 'n_fuente_agua_camion',\n",
    "        'description': 'Viviendas con origen del agua por camion aljibe',\n",
    "        'priority': 3\n",
    "    },\n",
    "    'rio': {\n",
    "        'name': 'Rio/Vertiente/Estero',\n",
    "        'name_short': 'Rio',\n",
    "        'col_2017': 'VIV_AGUA_1',\n",
    "        'col_2024': 'n_fuente_agua_rio',\n",
    "        'description': 'Viviendas con origen del agua por rio, vertiente, estero, canal, lago, etc.',\n",
    "        'priority': 4\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_output_folder(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    subfolders = ['Excel', 'Shapefiles', 'Reportes', 'Hotspots', 'Statistics', 'Water_Analysis', 'Census_Data']\n",
    "    for f in subfolders:\n",
    "        Path(os.path.join(path, f)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_reference_layer(layer_config):\n",
    "    path = layer_config['path']\n",
    "    prefix = layer_config['prefix']\n",
    "    native_crs = layer_config['native_crs']\n",
    "    is_gdb = layer_config['is_gdb']\n",
    "    layer_name = layer_config.get('layer_name')\n",
    "    name_col = layer_config['name_col']\n",
    "    code_col = layer_config['code_col']\n",
    "    \n",
    "    try:\n",
    "        if is_gdb:\n",
    "            gdf = gpd.read_file(path, layer=layer_name)\n",
    "        else:\n",
    "            gdf = gpd.read_file(path)\n",
    "        \n",
    "        if gdf.crs is None:\n",
    "            gdf = gdf.set_crs(native_crs)\n",
    "        \n",
    "        if gdf.crs.to_string() != TARGET_CRS:\n",
    "            gdf = gdf.to_crs(TARGET_CRS)\n",
    "        \n",
    "        available_cols = gdf.columns.tolist()\n",
    "        \n",
    "        if name_col not in available_cols:\n",
    "            for col in available_cols:\n",
    "                if 'name' in col.lower() or 'nom' in col.lower():\n",
    "                    name_col = col\n",
    "                    break\n",
    "        \n",
    "        if code_col not in available_cols:\n",
    "            for col in available_cols:\n",
    "                if 'cod' in col.lower() or 'id' in col.lower():\n",
    "                    code_col = col\n",
    "                    break\n",
    "        \n",
    "        cols_to_keep = ['geometry']\n",
    "        if name_col in gdf.columns:\n",
    "            cols_to_keep.append(name_col)\n",
    "        if code_col in gdf.columns and code_col != name_col:\n",
    "            cols_to_keep.append(code_col)\n",
    "        \n",
    "        gdf = gdf[cols_to_keep].copy()\n",
    "        \n",
    "        rename_dict = {}\n",
    "        if name_col in gdf.columns:\n",
    "            rename_dict[name_col] = f'{prefix}_Name'\n",
    "        if code_col in gdf.columns and code_col != name_col:\n",
    "            rename_dict[code_col] = f'{prefix}_Code'\n",
    "        \n",
    "        gdf = gdf.rename(columns=rename_dict)\n",
    "        \n",
    "        return gdf, prefix\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading {prefix}: {str(e)}\")\n",
    "        return None, prefix\n",
    "\n",
    "def perform_spatial_join(gdf_points, gdf_polygons, prefix):\n",
    "    if gdf_points is None or len(gdf_points) == 0:\n",
    "        return gdf_points\n",
    "    \n",
    "    if gdf_polygons is None or len(gdf_polygons) == 0:\n",
    "        return gdf_points\n",
    "    \n",
    "    if gdf_points.crs != gdf_polygons.crs:\n",
    "        gdf_polygons = gdf_polygons.to_crs(gdf_points.crs)\n",
    "    \n",
    "    cols_to_drop = [col for col in gdf_points.columns if col.startswith('index_')]\n",
    "    if cols_to_drop:\n",
    "        gdf_points = gdf_points.drop(columns=cols_to_drop)\n",
    "    \n",
    "    gdf_points = gdf_points.reset_index(drop=True)\n",
    "    gdf_polygons = gdf_polygons.reset_index(drop=True)\n",
    "    \n",
    "    try:\n",
    "        gdf_joined = gpd.sjoin(\n",
    "            gdf_points, \n",
    "            gdf_polygons, \n",
    "            how='left', \n",
    "            predicate='within'\n",
    "        )\n",
    "        \n",
    "        cols_to_drop = [col for col in gdf_joined.columns if col.startswith('index_')]\n",
    "        if cols_to_drop:\n",
    "            gdf_joined = gdf_joined.drop(columns=cols_to_drop)\n",
    "        \n",
    "        gdf_joined = gdf_joined.reset_index(drop=True)\n",
    "        \n",
    "        return gdf_joined\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in spatial join: {str(e)}\")\n",
    "        return gdf_points\n",
    "\n",
    "def buffer_shac_for_spatial_join(gdf_shac, buffer_distance_meters=200):\n",
    "    original_crs = gdf_shac.crs\n",
    "    \n",
    "    gdf_projected = gdf_shac.to_crs('EPSG:32719')\n",
    "    \n",
    "    gdf_buffered = gdf_projected.copy()\n",
    "    gdf_buffered['geometry'] = gdf_projected.geometry.buffer(buffer_distance_meters)\n",
    "    \n",
    "    gdf_buffered = gdf_buffered.to_crs(original_crs)\n",
    "    \n",
    "    return gdf_buffered\n",
    "\n",
    "def get_centroid_gdf(gdf):\n",
    "    gdf_copy = gdf.copy()\n",
    "    gdf_copy['_original_geometry'] = gdf_copy.geometry\n",
    "    gdf_copy['geometry'] = gdf_copy.geometry.centroid\n",
    "    return gdf_copy\n",
    "\n",
    "def restore_original_geometry(gdf):\n",
    "    if '_original_geometry' in gdf.columns:\n",
    "        gdf['geometry'] = gdf['_original_geometry']\n",
    "        gdf = gdf.drop(columns=['_original_geometry'])\n",
    "    return gdf\n",
    "\n",
    "def add_centroid_coordinates(gdf):\n",
    "    gdf = gdf.copy()\n",
    "    centroids = gdf.geometry.centroid\n",
    "    gdf['Centroid_Lon'] = centroids.x\n",
    "    gdf['Centroid_Lat'] = centroids.y\n",
    "    return gdf\n",
    "\n",
    "def calculate_water_statistics(gdf, groupby_col, year_suffix, area_filter=None):\n",
    "    if groupby_col not in gdf.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    gdf_filtered = gdf[gdf[groupby_col].notna()].copy()\n",
    "    \n",
    "    if area_filter is not None and f'Is_Rural_{year_suffix}' in gdf_filtered.columns:\n",
    "        if area_filter == 'Rural':\n",
    "            gdf_filtered = gdf_filtered[gdf_filtered[f'Is_Rural_{year_suffix}'] == 1]\n",
    "        elif area_filter == 'Urban':\n",
    "            gdf_filtered = gdf_filtered[gdf_filtered[f'Is_Rural_{year_suffix}'] == 0]\n",
    "    \n",
    "    if len(gdf_filtered) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    agg_dict = {\n",
    "        f'N_Blocks_{year_suffix}': (groupby_col, 'count'),\n",
    "        f'Total_Personas_{year_suffix}': (f'Personas_{year_suffix}', 'sum'),\n",
    "        f'Total_Viviendas_{year_suffix}': (f'Viviendas_{year_suffix}', 'sum'),\n",
    "    }\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_name = f\"{src_info['name_short']}_{year_suffix}\"\n",
    "        if col_name in gdf_filtered.columns:\n",
    "            agg_dict[f'Total_{src_info[\"name_short\"]}_{year_suffix}'] = (col_name, 'sum')\n",
    "    \n",
    "    if f'Is_Rural_{year_suffix}' in gdf_filtered.columns:\n",
    "        agg_dict[f'Rural_Blocks_{year_suffix}'] = (f'Is_Rural_{year_suffix}', 'sum')\n",
    "    \n",
    "    stats = gdf_filtered.groupby(groupby_col).agg(**agg_dict).reset_index()\n",
    "    \n",
    "    stats[f'Urban_Blocks_{year_suffix}'] = stats[f'N_Blocks_{year_suffix}'] - stats.get(f'Rural_Blocks_{year_suffix}', 0)\n",
    "    \n",
    "    stats[f'Avg_Persons_Per_Household_{year_suffix}'] = (\n",
    "        stats[f'Total_Personas_{year_suffix}'] / stats[f'Total_Viviendas_{year_suffix}'].replace(0, np.nan)\n",
    "    ).round(2)\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_total = f\"Total_{src_info['name_short']}_{year_suffix}\"\n",
    "        col_pct = f\"Pct_{src_info['name_short']}_{year_suffix}\"\n",
    "        if col_total in stats.columns:\n",
    "            stats[col_pct] = (\n",
    "                stats[col_total] / stats[f'Total_Viviendas_{year_suffix}'].replace(0, np.nan) * 100\n",
    "            ).round(2)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def calculate_national_water_statistics(gdf, year_suffix, area_filter=None):\n",
    "    gdf_filtered = gdf.copy()\n",
    "    \n",
    "    if area_filter is not None and f'Is_Rural_{year_suffix}' in gdf_filtered.columns:\n",
    "        if area_filter == 'Rural':\n",
    "            gdf_filtered = gdf_filtered[gdf_filtered[f'Is_Rural_{year_suffix}'] == 1]\n",
    "        elif area_filter == 'Urban':\n",
    "            gdf_filtered = gdf_filtered[gdf_filtered[f'Is_Rural_{year_suffix}'] == 0]\n",
    "    \n",
    "    results = {\n",
    "        f'N_Blocks_{year_suffix}': len(gdf_filtered),\n",
    "        f'Total_Personas_{year_suffix}': gdf_filtered[f'Personas_{year_suffix}'].sum(),\n",
    "        f'Total_Viviendas_{year_suffix}': gdf_filtered[f'Viviendas_{year_suffix}'].sum(),\n",
    "    }\n",
    "    \n",
    "    if f'Is_Rural_{year_suffix}' in gdf_filtered.columns:\n",
    "        results[f'Rural_Blocks_{year_suffix}'] = gdf_filtered[f'Is_Rural_{year_suffix}'].sum()\n",
    "        results[f'Urban_Blocks_{year_suffix}'] = len(gdf_filtered) - results[f'Rural_Blocks_{year_suffix}']\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_name = f\"{src_info['name_short']}_{year_suffix}\"\n",
    "        if col_name in gdf_filtered.columns:\n",
    "            results[f'Total_{src_info[\"name_short\"]}_{year_suffix}'] = gdf_filtered[col_name].sum()\n",
    "    \n",
    "    results[f'Avg_Persons_Per_Household_{year_suffix}'] = (\n",
    "        results[f'Total_Personas_{year_suffix}'] / results[f'Total_Viviendas_{year_suffix}']\n",
    "    ) if results[f'Total_Viviendas_{year_suffix}'] > 0 else 0\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_total = f\"Total_{src_info['name_short']}_{year_suffix}\"\n",
    "        col_pct = f\"Pct_{src_info['name_short']}_{year_suffix}\"\n",
    "        if col_total in results:\n",
    "            results[col_pct] = (\n",
    "                results[col_total] / results[f'Total_Viviendas_{year_suffix}'] * 100\n",
    "            ) if results[f'Total_Viviendas_{year_suffix}'] > 0 else 0\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_change_metrics(df, suffix_17='17', suffix_24='24'):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if f'N_Blocks_{suffix_17}' in df.columns and f'N_Blocks_{suffix_24}' in df.columns:\n",
    "        df['Cambio_Blocks'] = df[f'N_Blocks_{suffix_24}'] - df[f'N_Blocks_{suffix_17}']\n",
    "        df['Cambio_Blocks_Pct'] = (df['Cambio_Blocks'] / df[f'N_Blocks_{suffix_17}'].replace(0, np.nan)) * 100\n",
    "    \n",
    "    if f'Total_Viviendas_{suffix_17}' in df.columns and f'Total_Viviendas_{suffix_24}' in df.columns:\n",
    "        df['Cambio_Viviendas'] = df[f'Total_Viviendas_{suffix_24}'] - df[f'Total_Viviendas_{suffix_17}']\n",
    "        df['Cambio_Viviendas_Pct'] = (df['Cambio_Viviendas'] / df[f'Total_Viviendas_{suffix_17}'].replace(0, np.nan)) * 100\n",
    "    \n",
    "    if f'Total_Personas_{suffix_17}' in df.columns and f'Total_Personas_{suffix_24}' in df.columns:\n",
    "        df['Cambio_Personas'] = df[f'Total_Personas_{suffix_24}'] - df[f'Total_Personas_{suffix_17}']\n",
    "        df['Cambio_Personas_Pct'] = (df['Cambio_Personas'] / df[f'Total_Personas_{suffix_17}'].replace(0, np.nan)) * 100\n",
    "    \n",
    "    if f'Avg_Persons_Per_Household_{suffix_17}' in df.columns and f'Avg_Persons_Per_Household_{suffix_24}' in df.columns:\n",
    "        df['Cambio_Avg_Persons_Per_Household'] = df[f'Avg_Persons_Per_Household_{suffix_24}'] - df[f'Avg_Persons_Per_Household_{suffix_17}']\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_17 = f\"Total_{src_info['name_short']}_{suffix_17}\"\n",
    "        col_24 = f\"Total_{src_info['name_short']}_{suffix_24}\"\n",
    "        \n",
    "        if col_17 in df.columns and col_24 in df.columns:\n",
    "            df[f'Cambio_{src_info[\"name_short\"]}'] = df[col_24] - df[col_17]\n",
    "            df[f'Cambio_{src_info[\"name_short\"]}_Pct'] = (\n",
    "                df[f'Cambio_{src_info[\"name_short\"]}'] / df[col_17].replace(0, np.nan)\n",
    "            ) * 100\n",
    "            \n",
    "            pct_17 = f'Pct_{src_info[\"name_short\"]}_{suffix_17}'\n",
    "            pct_24 = f'Pct_{src_info[\"name_short\"]}_{suffix_24}'\n",
    "            \n",
    "            if pct_17 in df.columns and pct_24 in df.columns:\n",
    "                df[f'Cambio_PctViv_{src_info[\"name_short\"]}'] = df[pct_24] - df[pct_17]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def identify_water_scarcity_hotspots(df, name_col):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['Hotspot_Type'] = 'Normal'\n",
    "    df['Hotspot_Score'] = 0\n",
    "    df['Hotspot_Description'] = ''\n",
    "    \n",
    "    pozo_cambio = 'Cambio_Pozo'\n",
    "    camion_cambio = 'Cambio_Camion'\n",
    "    rio_cambio = 'Cambio_Rio'\n",
    "    red_cambio = 'Cambio_RedPublica'\n",
    "    \n",
    "    pozo_pct_cambio = 'Cambio_Pozo_Pct'\n",
    "    camion_pct_cambio = 'Cambio_Camion_Pct'\n",
    "    \n",
    "    required_cols = [pozo_cambio, camion_cambio, rio_cambio]\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        return df\n",
    "    \n",
    "    mask_camion_increase = df[camion_cambio] > 0\n",
    "    mask_pozo_decrease = df[pozo_cambio] < 0\n",
    "    mask_rio_decrease = df[rio_cambio] < 0\n",
    "    mask_red_decrease = df[red_cambio] < 0 if red_cambio in df.columns else pd.Series([False] * len(df))\n",
    "    \n",
    "    mask_critical = mask_camion_increase & mask_pozo_decrease & mask_rio_decrease\n",
    "    df.loc[mask_critical, 'Hotspot_Type'] = 'Critical_Water_Stress'\n",
    "    df.loc[mask_critical, 'Hotspot_Score'] = 5\n",
    "    df.loc[mask_critical, 'Hotspot_Description'] = 'Pozo decreases, Camion increases, Rio decreases - Severe water stress'\n",
    "    \n",
    "    mask_aquifer_drought = mask_pozo_decrease & mask_camion_increase & ~mask_critical\n",
    "    df.loc[mask_aquifer_drought, 'Hotspot_Type'] = 'Potential_Aquifer_Drought'\n",
    "    df.loc[mask_aquifer_drought, 'Hotspot_Score'] = 4\n",
    "    df.loc[mask_aquifer_drought, 'Hotspot_Description'] = 'Well access decreased, water truck increased - Groundwater depletion'\n",
    "    \n",
    "    mask_surface_stress = mask_camion_increase & mask_rio_decrease & ~mask_critical & ~mask_aquifer_drought\n",
    "    df.loc[mask_surface_stress, 'Hotspot_Type'] = 'Surface_Water_Stress'\n",
    "    df.loc[mask_surface_stress, 'Hotspot_Score'] = 3\n",
    "    df.loc[mask_surface_stress, 'Hotspot_Description'] = 'Camion increases, Rio decreases - Surface water stress'\n",
    "    \n",
    "    mask_general_stress = mask_pozo_decrease & mask_rio_decrease & ~mask_camion_increase & ~mask_critical\n",
    "    df.loc[mask_general_stress, 'Hotspot_Type'] = 'General_Water_Decline'\n",
    "    df.loc[mask_general_stress, 'Hotspot_Score'] = 3\n",
    "    df.loc[mask_general_stress, 'Hotspot_Description'] = 'Both Pozo and Rio decrease - General water availability decline'\n",
    "    \n",
    "    mask_emerging = mask_camion_increase & ~mask_pozo_decrease & ~mask_rio_decrease\n",
    "    df.loc[mask_emerging, 'Hotspot_Type'] = 'Emerging_Water_Gap'\n",
    "    df.loc[mask_emerging, 'Hotspot_Score'] = 2\n",
    "    df.loc[mask_emerging, 'Hotspot_Description'] = 'Camion increases while other sources stable - Infrastructure gap'\n",
    "    \n",
    "    pct_pozo_24 = 'Pct_Pozo_24'\n",
    "    pct_camion_24 = 'Pct_Camion_24'\n",
    "    pct_rio_24 = 'Pct_Rio_24'\n",
    "    \n",
    "    if all(col in df.columns for col in [pct_pozo_24, pct_camion_24, pct_rio_24]):\n",
    "        mask_high_dependency = (\n",
    "            (df[pct_pozo_24] > 30) | \n",
    "            (df[pct_camion_24] > 10) | \n",
    "            (df[pct_rio_24] > 20)\n",
    "        )\n",
    "        df.loc[mask_high_dependency & (df['Hotspot_Type'] == 'Normal'), 'Hotspot_Type'] = 'High_Alt_Source_Dependency'\n",
    "        df.loc[mask_high_dependency & (df['Hotspot_Score'] == 0), 'Hotspot_Score'] = 1\n",
    "        df.loc[mask_high_dependency & (df['Hotspot_Description'] == ''), 'Hotspot_Description'] = 'High dependency on alternative water sources'\n",
    "    \n",
    "    if camion_pct_cambio in df.columns:\n",
    "        high_camion_increase = df[camion_pct_cambio] > 50\n",
    "        df.loc[high_camion_increase, 'Hotspot_Score'] = df.loc[high_camion_increase, 'Hotspot_Score'] + 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "def identify_well_increase_areas(df, name_col):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['Well_Trend'] = 'Stable'\n",
    "    df['Well_Trend_Score'] = 0\n",
    "    df['Well_Trend_Description'] = ''\n",
    "    \n",
    "    pozo_cambio = 'Cambio_Pozo'\n",
    "    pozo_pct_cambio = 'Cambio_Pozo_Pct'\n",
    "    pct_pozo_24 = 'Pct_Pozo_24'\n",
    "    \n",
    "    if pozo_cambio not in df.columns:\n",
    "        return df\n",
    "    \n",
    "    mask_significant_increase = (df[pozo_cambio] > 0) & (df[pozo_pct_cambio] > 20)\n",
    "    df.loc[mask_significant_increase, 'Well_Trend'] = 'Significant_Well_Increase'\n",
    "    df.loc[mask_significant_increase, 'Well_Trend_Score'] = 3\n",
    "    df.loc[mask_significant_increase, 'Well_Trend_Description'] = 'Significant increase in well-dependent households (>20%)'\n",
    "    \n",
    "    mask_moderate_increase = (df[pozo_cambio] > 0) & (df[pozo_pct_cambio] > 10) & (df[pozo_pct_cambio] <= 20)\n",
    "    df.loc[mask_moderate_increase & (df['Well_Trend'] == 'Stable'), 'Well_Trend'] = 'Moderate_Well_Increase'\n",
    "    df.loc[mask_moderate_increase & (df['Well_Trend_Score'] == 0), 'Well_Trend_Score'] = 2\n",
    "    df.loc[mask_moderate_increase & (df['Well_Trend_Description'] == ''), 'Well_Trend_Description'] = 'Moderate increase in well-dependent households (10-20%)'\n",
    "    \n",
    "    mask_slight_increase = (df[pozo_cambio] > 0) & (df[pozo_pct_cambio] <= 10)\n",
    "    df.loc[mask_slight_increase & (df['Well_Trend'] == 'Stable'), 'Well_Trend'] = 'Slight_Well_Increase'\n",
    "    df.loc[mask_slight_increase & (df['Well_Trend_Score'] == 0), 'Well_Trend_Score'] = 1\n",
    "    df.loc[mask_slight_increase & (df['Well_Trend_Description'] == ''), 'Well_Trend_Description'] = 'Slight increase in well-dependent households (<10%)'\n",
    "    \n",
    "    mask_decrease = df[pozo_cambio] < 0\n",
    "    df.loc[mask_decrease, 'Well_Trend'] = 'Well_Decrease'\n",
    "    df.loc[mask_decrease, 'Well_Trend_Score'] = -1\n",
    "    df.loc[mask_decrease, 'Well_Trend_Description'] = 'Decrease in well-dependent households'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def identify_well_to_truck_transition(df, name_col):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['Transition_Type'] = 'No_Transition'\n",
    "    df['Transition_Score'] = 0\n",
    "    df['Transition_Description'] = ''\n",
    "    \n",
    "    pozo_cambio = 'Cambio_Pozo'\n",
    "    camion_cambio = 'Cambio_Camion'\n",
    "    pct_pozo_17 = 'Pct_Pozo_17'\n",
    "    pct_camion_24 = 'Pct_Camion_24'\n",
    "    \n",
    "    required_cols = [pozo_cambio, camion_cambio]\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        return df\n",
    "    \n",
    "    mask_was_well_based = df[pct_pozo_17] > 15 if pct_pozo_17 in df.columns else pd.Series([True] * len(df))\n",
    "    mask_pozo_decrease = df[pozo_cambio] < 0\n",
    "    mask_camion_increase = df[camion_cambio] > 0\n",
    "    \n",
    "    mask_critical_transition = mask_was_well_based & mask_pozo_decrease & mask_camion_increase\n",
    "    df.loc[mask_critical_transition, 'Transition_Type'] = 'Well_to_Truck_Critical'\n",
    "    df.loc[mask_critical_transition, 'Transition_Score'] = 5\n",
    "    df.loc[mask_critical_transition, 'Transition_Description'] = 'Was primarily well-based, now shifting to water truck - POTENTIAL AQUIFER DROUGHT'\n",
    "    \n",
    "    mask_moderate_transition = ~mask_was_well_based & mask_pozo_decrease & mask_camion_increase\n",
    "    df.loc[mask_moderate_transition, 'Transition_Type'] = 'Well_to_Truck_Moderate'\n",
    "    df.loc[mask_moderate_transition, 'Transition_Score'] = 3\n",
    "    df.loc[mask_moderate_transition, 'Transition_Description'] = 'Well access decreasing, water truck increasing - Groundwater stress'\n",
    "    \n",
    "    mask_camion_dependency = (df[pct_camion_24] > 20) if pct_camion_24 in df.columns else pd.Series([False] * len(df))\n",
    "    df.loc[mask_camion_dependency & (df['Transition_Type'] == 'No_Transition'), 'Transition_Type'] = 'High_Truck_Dependency'\n",
    "    df.loc[mask_camion_dependency & (df['Transition_Score'] == 0), 'Transition_Score'] = 2\n",
    "    df.loc[mask_camion_dependency & (df['Transition_Description'] == ''), 'Transition_Description'] = 'High dependency on water trucks (>20%)'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_water_analysis_report(stats_17, stats_24, stats_merged, level_name, name_col, report_lines, area_type='All'):\n",
    "    area_label = f\" - {area_type}\" if area_type != 'All' else \"\"\n",
    "    \n",
    "    report_lines.append(f\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(f\"WATER SOURCE ANALYSIS - {level_name.upper()}{area_label}\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    report_lines.append(f\"\\n--- SUMMARY STATISTICS ---\")\n",
    "    report_lines.append(f\"Total units analyzed: {len(stats_merged)}\")\n",
    "    \n",
    "    total_viv_17 = stats_merged['Total_Viviendas_17'].sum() if 'Total_Viviendas_17' in stats_merged.columns else 0\n",
    "    total_viv_24 = stats_merged['Total_Viviendas_24'].sum() if 'Total_Viviendas_24' in stats_merged.columns else 0\n",
    "    total_pers_17 = stats_merged['Total_Personas_17'].sum() if 'Total_Personas_17' in stats_merged.columns else 0\n",
    "    total_pers_24 = stats_merged['Total_Personas_24'].sum() if 'Total_Personas_24' in stats_merged.columns else 0\n",
    "    \n",
    "    report_lines.append(f\"\\nPopulation: {total_pers_17:,.0f} (2017) -> {total_pers_24:,.0f} (2024) | Change: {total_pers_24-total_pers_17:+,.0f} ({((total_pers_24/total_pers_17)-1)*100 if total_pers_17 > 0 else 0:+.1f}%)\")\n",
    "    report_lines.append(f\"Households: {total_viv_17:,.0f} (2017) -> {total_viv_24:,.0f} (2024) | Change: {total_viv_24-total_viv_17:+,.0f} ({((total_viv_24/total_viv_17)-1)*100 if total_viv_17 > 0 else 0:+.1f}%)\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- WATER SOURCES COMPARISON ---\")\n",
    "    report_lines.append(f\"{'Source':<25} {'2017':>15} {'2024':>15} {'Change':>15} {'%':>10} {'%Viv 17':>10} {'%Viv 24':>10}\")\n",
    "    report_lines.append(\"-\"*100)\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_17 = f\"Total_{src_info['name_short']}_17\"\n",
    "        col_24 = f\"Total_{src_info['name_short']}_24\"\n",
    "        \n",
    "        val_17 = stats_merged[col_17].sum() if col_17 in stats_merged.columns else 0\n",
    "        val_24 = stats_merged[col_24].sum() if col_24 in stats_merged.columns else 0\n",
    "        change = val_24 - val_17\n",
    "        pct_change = ((val_24 / val_17) - 1) * 100 if val_17 > 0 else 0\n",
    "        pct_viv_17 = (val_17 / total_viv_17) * 100 if total_viv_17 > 0 else 0\n",
    "        pct_viv_24 = (val_24 / total_viv_24) * 100 if total_viv_24 > 0 else 0\n",
    "        \n",
    "        report_lines.append(f\"{src_info['name']:<25} {val_17:>15,.0f} {val_24:>15,.0f} {change:>+15,.0f} {pct_change:>+9.1f}% {pct_viv_17:>9.2f}% {pct_viv_24:>9.2f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- TOP 10: HIGHEST WELL (POZO) INCREASE ---\")\n",
    "    if 'Cambio_Pozo' in stats_merged.columns:\n",
    "        top_pozo_increase = stats_merged[stats_merged['Cambio_Pozo'] > 0].nlargest(10, 'Cambio_Pozo')\n",
    "        report_lines.append(f\"{'Rank':<5} {level_name:<35} {'Pozo 17':>12} {'Pozo 24':>12} {'Change':>12} {'%':>10}\")\n",
    "        report_lines.append(\"-\"*90)\n",
    "        for i, (_, row) in enumerate(top_pozo_increase.iterrows(), 1):\n",
    "            name = str(row[name_col])[:33] if pd.notna(row.get(name_col)) else \"N/A\"\n",
    "            p17 = row.get('Total_Pozo_17', 0)\n",
    "            p24 = row.get('Total_Pozo_24', 0)\n",
    "            chg = row.get('Cambio_Pozo', 0)\n",
    "            pct = row.get('Cambio_Pozo_Pct', 0)\n",
    "            report_lines.append(f\"{i:<5} {name:<35} {p17:>12,.0f} {p24:>12,.0f} {chg:>+12,.0f} {pct:>+9.1f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- TOP 10: HIGHEST WELL (POZO) PERCENTAGE INCREASE ---\")\n",
    "    if 'Cambio_Pozo_Pct' in stats_merged.columns:\n",
    "        valid_pct = stats_merged[(stats_merged['Total_Pozo_17'] > 10) & (stats_merged['Cambio_Pozo_Pct'].notna())]\n",
    "        top_pozo_pct = valid_pct.nlargest(10, 'Cambio_Pozo_Pct')\n",
    "        report_lines.append(f\"{'Rank':<5} {level_name:<35} {'Pozo 17':>12} {'Pozo 24':>12} {'Change':>12} {'%':>10}\")\n",
    "        report_lines.append(\"-\"*90)\n",
    "        for i, (_, row) in enumerate(top_pozo_pct.iterrows(), 1):\n",
    "            name = str(row[name_col])[:33] if pd.notna(row.get(name_col)) else \"N/A\"\n",
    "            p17 = row.get('Total_Pozo_17', 0)\n",
    "            p24 = row.get('Total_Pozo_24', 0)\n",
    "            chg = row.get('Cambio_Pozo', 0)\n",
    "            pct = row.get('Cambio_Pozo_Pct', 0)\n",
    "            report_lines.append(f\"{i:<5} {name:<35} {p17:>12,.0f} {p24:>12,.0f} {chg:>+12,.0f} {pct:>+9.1f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- TOP 10: HIGHEST WATER TRUCK (CAMION) INCREASE ---\")\n",
    "    if 'Cambio_Camion' in stats_merged.columns:\n",
    "        top_camion = stats_merged[stats_merged['Cambio_Camion'] > 0].nlargest(10, 'Cambio_Camion')\n",
    "        report_lines.append(f\"{'Rank':<5} {level_name:<35} {'Camion 17':>12} {'Camion 24':>12} {'Change':>12} {'%':>10}\")\n",
    "        report_lines.append(\"-\"*90)\n",
    "        for i, (_, row) in enumerate(top_camion.iterrows(), 1):\n",
    "            name = str(row[name_col])[:33] if pd.notna(row.get(name_col)) else \"N/A\"\n",
    "            c17 = row.get('Total_Camion_17', 0)\n",
    "            c24 = row.get('Total_Camion_24', 0)\n",
    "            chg = row.get('Cambio_Camion', 0)\n",
    "            pct = row.get('Cambio_Camion_Pct', 0)\n",
    "            report_lines.append(f\"{i:<5} {name:<35} {c17:>12,.0f} {c24:>12,.0f} {chg:>+12,.0f} {pct:>+9.1f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- CRITICAL: WELL TO WATER TRUCK TRANSITION (Potential Aquifer Drought) ---\")\n",
    "    if 'Transition_Type' in stats_merged.columns:\n",
    "        critical_transition = stats_merged[stats_merged['Transition_Type'].isin(['Well_to_Truck_Critical', 'Well_to_Truck_Moderate'])]\n",
    "        critical_transition = critical_transition.sort_values('Transition_Score', ascending=False)\n",
    "        if len(critical_transition) > 0:\n",
    "            report_lines.append(f\"{'Rank':<5} {level_name:<30} {'Type':<25} {'Pozo Chg':>12} {'Camion Chg':>12}\")\n",
    "            report_lines.append(\"-\"*90)\n",
    "            for i, (_, row) in enumerate(critical_transition.head(15).iterrows(), 1):\n",
    "                name = str(row[name_col])[:28] if pd.notna(row.get(name_col)) else \"N/A\"\n",
    "                trans_type = row.get('Transition_Type', '')[:23]\n",
    "                pozo_chg = row.get('Cambio_Pozo', 0)\n",
    "                camion_chg = row.get('Cambio_Camion', 0)\n",
    "                report_lines.append(f\"{i:<5} {name:<30} {trans_type:<25} {pozo_chg:>+12,.0f} {camion_chg:>+12,.0f}\")\n",
    "        else:\n",
    "            report_lines.append(\"  No critical well-to-truck transitions identified.\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- WATER SCARCITY HOTSPOTS SUMMARY ---\")\n",
    "    if 'Hotspot_Type' in stats_merged.columns:\n",
    "        hotspot_counts = stats_merged['Hotspot_Type'].value_counts()\n",
    "        for htype, count in hotspot_counts.items():\n",
    "            if htype != 'Normal':\n",
    "                report_lines.append(f\"  {htype}: {count}\")\n",
    "    \n",
    "    return report_lines\n",
    "\n",
    "def generate_rural_urban_water_analysis(gdf_17, gdf_24, stats_all, level_name, name_col, report_lines):\n",
    "    report_lines.append(f\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(f\"RURAL vs URBAN WATER ANALYSIS - {level_name.upper()}\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    rural_17 = calculate_national_water_statistics(gdf_17, '17', 'Rural')\n",
    "    urban_17 = calculate_national_water_statistics(gdf_17, '17', 'Urban')\n",
    "    rural_24 = calculate_national_water_statistics(gdf_24, '24', 'Rural')\n",
    "    urban_24 = calculate_national_water_statistics(gdf_24, '24', 'Urban')\n",
    "    \n",
    "    report_lines.append(f\"\\n--- NATIONAL RURAL vs URBAN COMPARISON ---\")\n",
    "    report_lines.append(f\"\\n{'Metric':<35} {'Rural 17':>15} {'Rural 24':>15} {'Urban 17':>15} {'Urban 24':>15}\")\n",
    "    report_lines.append(\"-\"*100)\n",
    "    \n",
    "    report_lines.append(f\"{'Census Blocks':<35} {rural_17.get('N_Blocks_17', 0):>15,.0f} {rural_24.get('N_Blocks_24', 0):>15,.0f} {urban_17.get('N_Blocks_17', 0):>15,.0f} {urban_24.get('N_Blocks_24', 0):>15,.0f}\")\n",
    "    report_lines.append(f\"{'Population':<35} {rural_17.get('Total_Personas_17', 0):>15,.0f} {rural_24.get('Total_Personas_24', 0):>15,.0f} {urban_17.get('Total_Personas_17', 0):>15,.0f} {urban_24.get('Total_Personas_24', 0):>15,.0f}\")\n",
    "    report_lines.append(f\"{'Households':<35} {rural_17.get('Total_Viviendas_17', 0):>15,.0f} {rural_24.get('Total_Viviendas_24', 0):>15,.0f} {urban_17.get('Total_Viviendas_17', 0):>15,.0f} {urban_24.get('Total_Viviendas_24', 0):>15,.0f}\")\n",
    "    report_lines.append(f\"{'Avg Persons/Household':<35} {rural_17.get('Avg_Persons_Per_Household_17', 0):>15.2f} {rural_24.get('Avg_Persons_Per_Household_24', 0):>15.2f} {urban_17.get('Avg_Persons_Per_Household_17', 0):>15.2f} {urban_24.get('Avg_Persons_Per_Household_24', 0):>15.2f}\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- WATER SOURCES BY AREA TYPE ---\")\n",
    "    \n",
    "    for area_type, stats_17, stats_24 in [('RURAL', rural_17, rural_24), ('URBAN', urban_17, urban_24)]:\n",
    "        report_lines.append(f\"\\n  {area_type} AREAS:\")\n",
    "        report_lines.append(f\"  {'Source':<23} {'2017':>12} {'2024':>12} {'Change':>12} {'%':>10} {'%Viv 17':>10} {'%Viv 24':>10}\")\n",
    "        report_lines.append(\"  \" + \"-\"*90)\n",
    "        \n",
    "        for src_key, src_info in WATER_SOURCES.items():\n",
    "            col_17 = f\"Total_{src_info['name_short']}_17\"\n",
    "            col_24 = f\"Total_{src_info['name_short']}_24\"\n",
    "            \n",
    "            val_17 = stats_17.get(col_17, 0)\n",
    "            val_24 = stats_24.get(col_24, 0)\n",
    "            change = val_24 - val_17\n",
    "            pct_change = ((val_24 / val_17) - 1) * 100 if val_17 > 0 else 0\n",
    "            \n",
    "            total_viv_17 = stats_17.get('Total_Viviendas_17', 1)\n",
    "            total_viv_24 = stats_24.get('Total_Viviendas_24', 1)\n",
    "            pct_viv_17 = (val_17 / total_viv_17) * 100 if total_viv_17 > 0 else 0\n",
    "            pct_viv_24 = (val_24 / total_viv_24) * 100 if total_viv_24 > 0 else 0\n",
    "            \n",
    "            report_lines.append(f\"  {src_info['name']:<23} {val_17:>12,.0f} {val_24:>12,.0f} {change:>+12,.0f} {pct_change:>+9.1f}% {pct_viv_17:>9.2f}% {pct_viv_24:>9.2f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- KEY INSIGHT: RURAL WATER ACCESS CHANGES ---\")\n",
    "    \n",
    "    rural_pozo_17 = rural_17.get('Total_Pozo_17', 0)\n",
    "    rural_pozo_24 = rural_24.get('Total_Pozo_24', 0)\n",
    "    rural_camion_17 = rural_17.get('Total_Camion_17', 0)\n",
    "    rural_camion_24 = rural_24.get('Total_Camion_24', 0)\n",
    "    rural_rio_17 = rural_17.get('Total_Rio_17', 0)\n",
    "    rural_rio_24 = rural_24.get('Total_Rio_24', 0)\n",
    "    rural_red_17 = rural_17.get('Total_RedPublica_17', 0)\n",
    "    rural_red_24 = rural_24.get('Total_RedPublica_24', 0)\n",
    "    \n",
    "    report_lines.append(f\"\\n  Rural Well (Pozo) Access:\")\n",
    "    report_lines.append(f\"    2017: {rural_pozo_17:,.0f} households\")\n",
    "    report_lines.append(f\"    2024: {rural_pozo_24:,.0f} households\")\n",
    "    report_lines.append(f\"    Change: {rural_pozo_24-rural_pozo_17:+,.0f} ({((rural_pozo_24/rural_pozo_17)-1)*100 if rural_pozo_17 > 0 else 0:+.1f}%)\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  Rural Water Truck (Camion) Dependency:\")\n",
    "    report_lines.append(f\"    2017: {rural_camion_17:,.0f} households\")\n",
    "    report_lines.append(f\"    2024: {rural_camion_24:,.0f} households\")\n",
    "    report_lines.append(f\"    Change: {rural_camion_24-rural_camion_17:+,.0f} ({((rural_camion_24/rural_camion_17)-1)*100 if rural_camion_17 > 0 else 0:+.1f}%)\")\n",
    "    \n",
    "    if rural_camion_24 > rural_camion_17 and rural_pozo_24 < rural_pozo_17:\n",
    "        report_lines.append(f\"\\n  ⚠️ WARNING: Rural areas show well decrease with water truck increase - Potential groundwater stress\")\n",
    "    \n",
    "    return report_lines\n",
    "\n",
    "def generate_national_summary(gdf_17, gdf_24, report_lines):\n",
    "    report_lines.append(\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(\"NATIONAL SUMMARY - CHILE CENSUS 2017 vs 2024\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    nat_17 = calculate_national_water_statistics(gdf_17, '17')\n",
    "    nat_24 = calculate_national_water_statistics(gdf_24, '24')\n",
    "    \n",
    "    report_lines.append(f\"\\n--- CENSUS BLOCKS ---\")\n",
    "    report_lines.append(f\"  2017: {nat_17['N_Blocks_17']:,}\")\n",
    "    report_lines.append(f\"  2024: {nat_24['N_Blocks_24']:,}\")\n",
    "    block_change = nat_24['N_Blocks_24'] - nat_17['N_Blocks_17']\n",
    "    report_lines.append(f\"  Change: {block_change:+,} ({(block_change/nat_17['N_Blocks_17'])*100 if nat_17['N_Blocks_17'] > 0 else 0:+.1f}%)\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- POPULATION ---\")\n",
    "    report_lines.append(f\"  2017: {nat_17['Total_Personas_17']:,.0f}\")\n",
    "    report_lines.append(f\"  2024: {nat_24['Total_Personas_24']:,.0f}\")\n",
    "    pers_change = nat_24['Total_Personas_24'] - nat_17['Total_Personas_17']\n",
    "    report_lines.append(f\"  Change: {pers_change:+,.0f} ({(pers_change/nat_17['Total_Personas_17'])*100 if nat_17['Total_Personas_17'] > 0 else 0:+.1f}%)\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- HOUSEHOLDS ---\")\n",
    "    report_lines.append(f\"  2017: {nat_17['Total_Viviendas_17']:,.0f}\")\n",
    "    report_lines.append(f\"  2024: {nat_24['Total_Viviendas_24']:,.0f}\")\n",
    "    viv_change = nat_24['Total_Viviendas_24'] - nat_17['Total_Viviendas_17']\n",
    "    report_lines.append(f\"  Change: {viv_change:+,.0f} ({(viv_change/nat_17['Total_Viviendas_17'])*100 if nat_17['Total_Viviendas_17'] > 0 else 0:+.1f}%)\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- AVERAGE PERSONS PER HOUSEHOLD ---\")\n",
    "    report_lines.append(f\"  2017: {nat_17['Avg_Persons_Per_Household_17']:.2f}\")\n",
    "    report_lines.append(f\"  2024: {nat_24['Avg_Persons_Per_Household_24']:.2f}\")\n",
    "    report_lines.append(f\"  Change: {nat_24['Avg_Persons_Per_Household_24']-nat_17['Avg_Persons_Per_Household_17']:+.2f}\")\n",
    "    \n",
    "    rural_17 = nat_17.get('Rural_Blocks_17', 0)\n",
    "    urban_17 = nat_17.get('Urban_Blocks_17', 0)\n",
    "    rural_24 = nat_24.get('Rural_Blocks_24', 0)\n",
    "    urban_24 = nat_24.get('Urban_Blocks_24', 0)\n",
    "    \n",
    "    report_lines.append(f\"\\n--- RURAL vs URBAN BLOCKS ---\")\n",
    "    report_lines.append(f\"  Rural 2017: {rural_17:,.0f} | Urban 2017: {urban_17:,.0f}\")\n",
    "    report_lines.append(f\"  Rural 2024: {rural_24:,.0f} | Urban 2024: {urban_24:,.0f}\")\n",
    "    report_lines.append(f\"  Rural Change: {rural_24-rural_17:+,.0f} | Urban Change: {urban_24-urban_17:+,.0f}\")\n",
    "    \n",
    "    report_lines.append(f\"\\n--- NATIONAL WATER SOURCES SUMMARY ---\")\n",
    "    report_lines.append(f\"{'Source':<25} {'2017':>15} {'2024':>15} {'Change':>15} {'%':>10} {'%Viv 17':>10} {'%Viv 24':>10}\")\n",
    "    report_lines.append(\"-\"*100)\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_17 = f\"Total_{src_info['name_short']}_17\"\n",
    "        col_24 = f\"Total_{src_info['name_short']}_24\"\n",
    "        \n",
    "        val_17 = nat_17.get(col_17, 0)\n",
    "        val_24 = nat_24.get(col_24, 0)\n",
    "        change = val_24 - val_17\n",
    "        pct_change = ((val_24 / val_17) - 1) * 100 if val_17 > 0 else 0\n",
    "        pct_viv_17 = (val_17 / nat_17['Total_Viviendas_17']) * 100 if nat_17['Total_Viviendas_17'] > 0 else 0\n",
    "        pct_viv_24 = (val_24 / nat_24['Total_Viviendas_24']) * 100 if nat_24['Total_Viviendas_24'] > 0 else 0\n",
    "        \n",
    "        report_lines.append(f\"{src_info['name']:<25} {val_17:>15,.0f} {val_24:>15,.0f} {change:>+15,.0f} {pct_change:>+9.1f}% {pct_viv_17:>9.2f}% {pct_viv_24:>9.2f}%\")\n",
    "    \n",
    "    return report_lines, nat_17, nat_24\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"CENSUS 2017 vs 2024 WATER SOURCE ANALYSIS\")\n",
    "    print(\"With Spatial Joins to Reference Layers\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    create_output_folder(OUTPUT_FOLDER)\n",
    "    \n",
    "    report_lines = []\n",
    "    report_lines.append(\"=\"*100)\n",
    "    report_lines.append(\"CENSUS 2017 vs 2024 WATER SOURCE ANALYSIS REPORT\")\n",
    "    report_lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    print(\"\\nLoading reference layers...\")\n",
    "    reference_gdfs = {}\n",
    "    for layer_config in REFERENCE_LAYERS:\n",
    "        gdf, prefix = load_reference_layer(layer_config)\n",
    "        if gdf is not None:\n",
    "            reference_gdfs[prefix] = gdf\n",
    "            print(f\"  Loaded {prefix}: {len(gdf)} features\")\n",
    "    \n",
    "    print(f\"\\nLoaded {len(reference_gdfs)} reference layers: {list(reference_gdfs.keys())}\")\n",
    "    \n",
    "    print(\"\\nLoading Census 2017...\")\n",
    "    gdf_censo_2017 = gpd.read_file(GDB_PATH, layer=LAYER_CENSO_2017)\n",
    "    if gdf_censo_2017.crs != TARGET_CRS:\n",
    "        gdf_censo_2017 = gdf_censo_2017.to_crs(TARGET_CRS)\n",
    "    print(f\"  Loaded {len(gdf_censo_2017)} census blocks\")\n",
    "    \n",
    "    print(\"\\nLoading Census 2024...\")\n",
    "    gdf_censo_2024 = gpd.read_file(GDB_PATH, layer=LAYER_CENSO_2024)\n",
    "    if gdf_censo_2024.crs != TARGET_CRS:\n",
    "        gdf_censo_2024 = gdf_censo_2024.to_crs(TARGET_CRS)\n",
    "    print(f\"  Loaded {len(gdf_censo_2024)} census blocks\")\n",
    "    \n",
    "    print(\"\\nProcessing Census 2017...\")\n",
    "    \n",
    "    if COL_AREA_17 in gdf_censo_2017.columns:\n",
    "        gdf_censo_2017['Is_Rural_17'] = np.where(gdf_censo_2017[COL_AREA_17] == 2, 1, 0)\n",
    "    else:\n",
    "        gdf_censo_2017['Is_Rural_17'] = 0\n",
    "    \n",
    "    if COL_PERS_17 in gdf_censo_2017.columns:\n",
    "        gdf_censo_2017['Personas_17'] = pd.to_numeric(gdf_censo_2017[COL_PERS_17], errors='coerce').fillna(0)\n",
    "    else:\n",
    "        gdf_censo_2017['Personas_17'] = 0\n",
    "        print(f\"  WARNING: Column {COL_PERS_17} not found in Census 2017\")\n",
    "    \n",
    "    if COL_VIVIENDAS_17 in gdf_censo_2017.columns:\n",
    "        gdf_censo_2017['Viviendas_17'] = pd.to_numeric(gdf_censo_2017[COL_VIVIENDAS_17], errors='coerce').fillna(0)\n",
    "    else:\n",
    "        gdf_censo_2017['Viviendas_17'] = 0\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_orig = src_info['col_2017']\n",
    "        col_new = f\"{src_info['name_short']}_17\"\n",
    "        if col_orig in gdf_censo_2017.columns:\n",
    "            gdf_censo_2017[col_new] = pd.to_numeric(gdf_censo_2017[col_orig], errors='coerce').fillna(0)\n",
    "        else:\n",
    "            gdf_censo_2017[col_new] = 0\n",
    "            print(f\"  WARNING: Column {col_orig} not found in Census 2017\")\n",
    "    \n",
    "    print(\"\\nProcessing Census 2024...\")\n",
    "    \n",
    "    if COL_AREA_24 in gdf_censo_2024.columns:\n",
    "        gdf_censo_2024['Is_Rural_24'] = np.where(\n",
    "            gdf_censo_2024[COL_AREA_24].astype(str).str.upper().str.strip() == 'RURAL', 1, 0\n",
    "        )\n",
    "    else:\n",
    "        gdf_censo_2024['Is_Rural_24'] = 0\n",
    "    \n",
    "    if COL_PERS_24 in gdf_censo_2024.columns:\n",
    "        gdf_censo_2024['Personas_24'] = pd.to_numeric(gdf_censo_2024[COL_PERS_24], errors='coerce').fillna(0)\n",
    "    else:\n",
    "        gdf_censo_2024['Personas_24'] = 0\n",
    "        print(f\"  WARNING: Column {COL_PERS_24} not found in Census 2024\")\n",
    "    \n",
    "    if COL_VIVIENDAS_24 in gdf_censo_2024.columns:\n",
    "        gdf_censo_2024['Viviendas_24'] = pd.to_numeric(gdf_censo_2024[COL_VIVIENDAS_24], errors='coerce').fillna(0)\n",
    "    else:\n",
    "        gdf_censo_2024['Viviendas_24'] = 0\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_orig = src_info['col_2024']\n",
    "        col_new = f\"{src_info['name_short']}_24\"\n",
    "        if col_orig in gdf_censo_2024.columns:\n",
    "            gdf_censo_2024[col_new] = pd.to_numeric(gdf_censo_2024[col_orig], errors='coerce').fillna(0)\n",
    "        else:\n",
    "            gdf_censo_2024[col_new] = 0\n",
    "            print(f\"  WARNING: Column {col_orig} not found in Census 2024\")\n",
    "    \n",
    "    print(\"\\nPerforming spatial joins for Census 2017...\")\n",
    "    gdf_censo_2017_centroids = get_centroid_gdf(gdf_censo_2017)\n",
    "    for prefix, ref_gdf in reference_gdfs.items():\n",
    "        print(f\"  Joining with {prefix}...\")\n",
    "        if prefix == 'SHAC':\n",
    "            print(f\"    Applying {SHAC_BUFFER_DISTANCE}m buffer for SHAC spatial join...\")\n",
    "            ref_gdf_buffered = buffer_shac_for_spatial_join(ref_gdf, SHAC_BUFFER_DISTANCE)\n",
    "            gdf_censo_2017_centroids = perform_spatial_join(gdf_censo_2017_centroids, ref_gdf_buffered, prefix)\n",
    "        else:\n",
    "            gdf_censo_2017_centroids = perform_spatial_join(gdf_censo_2017_centroids, ref_gdf, prefix)\n",
    "    gdf_censo_2017_joined = restore_original_geometry(gdf_censo_2017_centroids)\n",
    "    gdf_censo_2017_joined = add_centroid_coordinates(gdf_censo_2017_joined)\n",
    "    \n",
    "    print(\"\\nPerforming spatial joins for Census 2024...\")\n",
    "    gdf_censo_2024_centroids = get_centroid_gdf(gdf_censo_2024)\n",
    "    for prefix, ref_gdf in reference_gdfs.items():\n",
    "        print(f\"  Joining with {prefix}...\")\n",
    "        if prefix == 'SHAC':\n",
    "            print(f\"    Applying {SHAC_BUFFER_DISTANCE}m buffer for SHAC spatial join...\")\n",
    "            ref_gdf_buffered = buffer_shac_for_spatial_join(ref_gdf, SHAC_BUFFER_DISTANCE)\n",
    "            gdf_censo_2024_centroids = perform_spatial_join(gdf_censo_2024_centroids, ref_gdf_buffered, prefix)\n",
    "        else:\n",
    "            gdf_censo_2024_centroids = perform_spatial_join(gdf_censo_2024_centroids, ref_gdf, prefix)\n",
    "    gdf_censo_2024_joined = restore_original_geometry(gdf_censo_2024_centroids)\n",
    "    gdf_censo_2024_joined = add_centroid_coordinates(gdf_censo_2024_joined)\n",
    "    \n",
    "    print(\"\\nSaving Census data with spatial joins...\")\n",
    "    \n",
    "    df_censo_2017_export = pd.DataFrame(gdf_censo_2017_joined.drop(columns='geometry'))\n",
    "    df_censo_2024_export = pd.DataFrame(gdf_censo_2024_joined.drop(columns='geometry'))\n",
    "    \n",
    "    censo_2017_path = os.path.join(OUTPUT_FOLDER, 'Census_Data', 'Census_2017_With_Spatial_Joins.xlsx')\n",
    "    censo_2024_path = os.path.join(OUTPUT_FOLDER, 'Census_Data', 'Census_2024_With_Spatial_Joins.xlsx')\n",
    "    \n",
    "    df_censo_2017_export.to_excel(censo_2017_path, index=False)\n",
    "    df_censo_2024_export.to_excel(censo_2024_path, index=False)\n",
    "    print(f\"  Saved: {censo_2017_path}\")\n",
    "    print(f\"  Saved: {censo_2024_path}\")\n",
    "\n",
    "    censo_2017_shp_path = os.path.join(OUTPUT_FOLDER, 'Shapefiles', 'Census_2017_With_Spatial_Joins.shp')\n",
    "    censo_2024_shp_path = os.path.join(OUTPUT_FOLDER, 'Shapefiles', 'Census_2024_With_Spatial_Joins.shp')\n",
    "    \n",
    "    gdf_censo_2017_joined.to_file(censo_2017_shp_path, driver='ESRI Shapefile')\n",
    "    gdf_censo_2024_joined.to_file(censo_2024_shp_path, driver='ESRI Shapefile')\n",
    "    \n",
    "    print(f\"  Saved Shapefile: {censo_2017_shp_path}\")\n",
    "    print(f\"  Saved Shapefile: {censo_2024_shp_path}\")\n",
    "    \n",
    "    print(\"\\nGenerating National Summary...\")\n",
    "    report_lines, nat_17, nat_24 = generate_national_summary(gdf_censo_2017, gdf_censo_2024, report_lines)\n",
    "    \n",
    "    report_lines = generate_rural_urban_water_analysis(\n",
    "        gdf_censo_2017, gdf_censo_2024, \n",
    "        None, 'National', 'National', report_lines\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCalculating statistics at multiple levels...\")\n",
    "    \n",
    "    all_stats = {}\n",
    "    \n",
    "    levels = [\n",
    "        ('Region', 'Region_Name'),\n",
    "        ('Muni', 'Muni_Name'),\n",
    "        ('Cuenca', 'Cuenca_Name'),\n",
    "        ('SHAC', 'SHAC_Name')\n",
    "    ]\n",
    "    \n",
    "    for level_prefix, name_col in levels:\n",
    "        print(f\"\\n  Processing {level_prefix} level...\")\n",
    "        \n",
    "        stats_17 = calculate_water_statistics(gdf_censo_2017_joined, name_col, '17')\n",
    "        stats_24 = calculate_water_statistics(gdf_censo_2024_joined, name_col, '24')\n",
    "        \n",
    "        stats_17_rural = calculate_water_statistics(gdf_censo_2017_joined, name_col, '17', 'Rural')\n",
    "        stats_17_urban = calculate_water_statistics(gdf_censo_2017_joined, name_col, '17', 'Urban')\n",
    "        stats_24_rural = calculate_water_statistics(gdf_censo_2024_joined, name_col, '24', 'Rural')\n",
    "        stats_24_urban = calculate_water_statistics(gdf_censo_2024_joined, name_col, '24', 'Urban')\n",
    "        \n",
    "        if len(stats_17) > 0 and len(stats_24) > 0:\n",
    "            stats_merged = stats_17.merge(stats_24, on=name_col, how='outer').fillna(0)\n",
    "            stats_merged = calculate_change_metrics(stats_merged)\n",
    "            stats_merged = identify_water_scarcity_hotspots(stats_merged, name_col)\n",
    "            stats_merged = identify_well_increase_areas(stats_merged, name_col)\n",
    "            stats_merged = identify_well_to_truck_transition(stats_merged, name_col)\n",
    "            \n",
    "            stats_merged_rural = pd.DataFrame()\n",
    "            stats_merged_urban = pd.DataFrame()\n",
    "            \n",
    "            if len(stats_17_rural) > 0 and len(stats_24_rural) > 0:\n",
    "                stats_merged_rural = stats_17_rural.merge(stats_24_rural, on=name_col, how='outer').fillna(0)\n",
    "                stats_merged_rural = calculate_change_metrics(stats_merged_rural)\n",
    "                stats_merged_rural = identify_water_scarcity_hotspots(stats_merged_rural, name_col)\n",
    "                stats_merged_rural = identify_well_increase_areas(stats_merged_rural, name_col)\n",
    "                stats_merged_rural = identify_well_to_truck_transition(stats_merged_rural, name_col)\n",
    "            \n",
    "            if len(stats_17_urban) > 0 and len(stats_24_urban) > 0:\n",
    "                stats_merged_urban = stats_17_urban.merge(stats_24_urban, on=name_col, how='outer').fillna(0)\n",
    "                stats_merged_urban = calculate_change_metrics(stats_merged_urban)\n",
    "                stats_merged_urban = identify_water_scarcity_hotspots(stats_merged_urban, name_col)\n",
    "            \n",
    "            all_stats[level_prefix] = {\n",
    "                'merged': stats_merged,\n",
    "                'stats_17': stats_17,\n",
    "                'stats_24': stats_24,\n",
    "                'merged_rural': stats_merged_rural,\n",
    "                'merged_urban': stats_merged_urban,\n",
    "            }\n",
    "            \n",
    "            print(f\"    {level_prefix}: {len(stats_merged)} units analyzed\")\n",
    "            \n",
    "            report_lines = generate_water_analysis_report(\n",
    "                stats_17, stats_24, stats_merged, \n",
    "                level_prefix, name_col, report_lines, 'All'\n",
    "            )\n",
    "            \n",
    "            if len(stats_merged_rural) > 0:\n",
    "                report_lines = generate_water_analysis_report(\n",
    "                    stats_17_rural, stats_24_rural, stats_merged_rural, \n",
    "                    level_prefix, name_col, report_lines, 'Rural'\n",
    "                )\n",
    "            \n",
    "            if len(stats_merged_urban) > 0:\n",
    "                report_lines = generate_water_analysis_report(\n",
    "                    stats_17_urban, stats_24_urban, stats_merged_urban, \n",
    "                    level_prefix, name_col, report_lines, 'Urban'\n",
    "                )\n",
    "    \n",
    "    print(\"\\nSaving outputs...\")\n",
    "    \n",
    "    for level_prefix, name_col in levels:\n",
    "        if level_prefix in all_stats:\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, 'Water_Analysis', f'Water_Analysis_{level_prefix}.xlsx')\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                all_stats[level_prefix]['merged'].to_excel(writer, sheet_name='All_Areas', index=False)\n",
    "                all_stats[level_prefix]['stats_17'].to_excel(writer, sheet_name='Census_2017', index=False)\n",
    "                all_stats[level_prefix]['stats_24'].to_excel(writer, sheet_name='Census_2024', index=False)\n",
    "                \n",
    "                if len(all_stats[level_prefix]['merged_rural']) > 0:\n",
    "                    all_stats[level_prefix]['merged_rural'].to_excel(writer, sheet_name='Rural_Areas', index=False)\n",
    "                if len(all_stats[level_prefix]['merged_urban']) > 0:\n",
    "                    all_stats[level_prefix]['merged_urban'].to_excel(writer, sheet_name='Urban_Areas', index=False)\n",
    "                \n",
    "                hotspots = all_stats[level_prefix]['merged'][\n",
    "                    all_stats[level_prefix]['merged']['Hotspot_Type'] != 'Normal'\n",
    "                ].sort_values('Hotspot_Score', ascending=False)\n",
    "                hotspots.to_excel(writer, sheet_name='Water_Hotspots', index=False)\n",
    "                \n",
    "                well_increase = all_stats[level_prefix]['merged'][\n",
    "                    all_stats[level_prefix]['merged']['Well_Trend'].str.contains('Increase', na=False)\n",
    "                ].sort_values('Well_Trend_Score', ascending=False)\n",
    "                well_increase.to_excel(writer, sheet_name='Well_Increase_Areas', index=False)\n",
    "                \n",
    "                transitions = all_stats[level_prefix]['merged'][\n",
    "                    all_stats[level_prefix]['merged']['Transition_Type'] != 'No_Transition'\n",
    "                ].sort_values('Transition_Score', ascending=False)\n",
    "                transitions.to_excel(writer, sheet_name='Well_to_Truck_Transitions', index=False)\n",
    "            \n",
    "            print(f\"  Saved {output_path}\")\n",
    "    \n",
    "    hotspots_all = []\n",
    "    well_increase_all = []\n",
    "    transitions_all = []\n",
    "    \n",
    "    for level_prefix, name_col in levels:\n",
    "        if level_prefix in all_stats:\n",
    "            df = all_stats[level_prefix]['merged'].copy()\n",
    "            df['Level'] = level_prefix\n",
    "            df['Unit_Name'] = df[name_col]\n",
    "            \n",
    "            hotspots_level = df[df['Hotspot_Type'] != 'Normal'].copy()\n",
    "            hotspots_all.append(hotspots_level)\n",
    "            \n",
    "            well_level = df[df['Well_Trend'].str.contains('Increase', na=False)].copy()\n",
    "            well_increase_all.append(well_level)\n",
    "            \n",
    "            trans_level = df[df['Transition_Type'] != 'No_Transition'].copy()\n",
    "            transitions_all.append(trans_level)\n",
    "    \n",
    "    if hotspots_all:\n",
    "        hotspots_combined = pd.concat(hotspots_all, ignore_index=True)\n",
    "        hotspots_path = os.path.join(OUTPUT_FOLDER, 'Hotspots', 'All_Water_Hotspots.xlsx')\n",
    "        with pd.ExcelWriter(hotspots_path, engine='openpyxl') as writer:\n",
    "            hotspots_combined.sort_values('Hotspot_Score', ascending=False).to_excel(writer, sheet_name='All_Hotspots', index=False)\n",
    "            for htype in hotspots_combined['Hotspot_Type'].unique():\n",
    "                if htype != 'Normal':\n",
    "                    filtered = hotspots_combined[hotspots_combined['Hotspot_Type'] == htype]\n",
    "                    sheet_name = htype[:31]\n",
    "                    filtered.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"  Saved {hotspots_path}\")\n",
    "    \n",
    "    if well_increase_all:\n",
    "        well_combined = pd.concat(well_increase_all, ignore_index=True)\n",
    "        well_path = os.path.join(OUTPUT_FOLDER, 'Hotspots', 'Well_Increase_Areas.xlsx')\n",
    "        well_combined.sort_values('Well_Trend_Score', ascending=False).to_excel(well_path, index=False)\n",
    "        print(f\"  Saved {well_path}\")\n",
    "    \n",
    "    if transitions_all:\n",
    "        trans_combined = pd.concat(transitions_all, ignore_index=True)\n",
    "        trans_path = os.path.join(OUTPUT_FOLDER, 'Hotspots', 'Well_to_Truck_Transitions.xlsx')\n",
    "        with pd.ExcelWriter(trans_path, engine='openpyxl') as writer:\n",
    "            trans_combined.sort_values('Transition_Score', ascending=False).to_excel(writer, sheet_name='All_Transitions', index=False)\n",
    "            critical = trans_combined[trans_combined['Transition_Type'] == 'Well_to_Truck_Critical']\n",
    "            if len(critical) > 0:\n",
    "                critical.to_excel(writer, sheet_name='Critical_Aquifer_Drought', index=False)\n",
    "        print(f\"  Saved {trans_path}\")\n",
    "    \n",
    "    national_summary = []\n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_17 = f\"Total_{src_info['name_short']}_17\"\n",
    "        col_24 = f\"Total_{src_info['name_short']}_24\"\n",
    "        \n",
    "        val_17 = nat_17.get(col_17, 0)\n",
    "        val_24 = nat_24.get(col_24, 0)\n",
    "        \n",
    "        national_summary.append({\n",
    "            'Water_Source': src_info['name'],\n",
    "            'Households_2017': val_17,\n",
    "            'Households_2024': val_24,\n",
    "            'Change_Absolute': val_24 - val_17,\n",
    "            'Change_Percent': ((val_24 / val_17) - 1) * 100 if val_17 > 0 else 0,\n",
    "            'Pct_Households_2017': (val_17 / nat_17['Total_Viviendas_17']) * 100 if nat_17['Total_Viviendas_17'] > 0 else 0,\n",
    "            'Pct_Households_2024': (val_24 / nat_24['Total_Viviendas_24']) * 100 if nat_24['Total_Viviendas_24'] > 0 else 0\n",
    "        })\n",
    "    \n",
    "    national_df = pd.DataFrame(national_summary)\n",
    "    national_path = os.path.join(OUTPUT_FOLDER, 'Statistics', 'National_Water_Summary.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(national_path, engine='openpyxl') as writer:\n",
    "        national_df.to_excel(writer, sheet_name='Water_Sources', index=False)\n",
    "        \n",
    "        overview = pd.DataFrame({\n",
    "            'Metric': ['Census Blocks', 'Population', 'Households', 'Avg Persons per Household',\n",
    "                      'Rural Blocks', 'Urban Blocks'],\n",
    "            '2017': [nat_17['N_Blocks_17'], nat_17['Total_Personas_17'], nat_17['Total_Viviendas_17'],\n",
    "                    nat_17['Avg_Persons_Per_Household_17'], nat_17.get('Rural_Blocks_17', 0), nat_17.get('Urban_Blocks_17', 0)],\n",
    "            '2024': [nat_24['N_Blocks_24'], nat_24['Total_Personas_24'], nat_24['Total_Viviendas_24'],\n",
    "                    nat_24['Avg_Persons_Per_Household_24'], nat_24.get('Rural_Blocks_24', 0), nat_24.get('Urban_Blocks_24', 0)]\n",
    "        })\n",
    "        overview['Change'] = overview['2024'] - overview['2017']\n",
    "        overview['Change_Pct'] = ((overview['2024'] / overview['2017']) - 1) * 100\n",
    "        overview.to_excel(writer, sheet_name='Overview', index=False)\n",
    "    \n",
    "    print(f\"  Saved {national_path}\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(\"ANALYSIS COMPLETE\")\n",
    "    report_lines.append(f\"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(f\"NOTE: SHAC spatial join uses {SHAC_BUFFER_DISTANCE}m buffer distance\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    report_path = os.path.join(OUTPUT_FOLDER, 'Reportes', f'Water_Analysis_Report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(report_lines))\n",
    "    print(f\"\\nReport saved: {report_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"\\n\".join(report_lines[:100]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-water]",
   "language": "python",
   "name": "conda-env-.conda-water-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
