{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1452a0-4869-4a6e-b3f5-8e785c680308",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6053970-c3b4-449f-abb9-da848a28a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DGA_CSV_PATH = r\"\\assessment_of_wells_chile\\data\\DGA\\DGA_dataset_analysis_output\\DGA_Data_Clean_With_Spatial_Joins.csv\"\n",
    "\n",
    "GDB_PATH = r\"\\assessment_of_wells_chile\\arcgis\\assessment_of_wells_chile\\Default.gdb\"\n",
    "LAYER_CENSO_2024 = \"Censo_24_Merge\"\n",
    "\n",
    "SHP_CUENCAS = r\"\\assessment_of_wells_chile\\data\\Basins\\Cuencas_BNA\\Cuencas_BNA.shp\"\n",
    "SHP_SHAC = r\"\\assessment_of_wells_chile\\data\\Aquifers\\INV_ACUIFEROS_SHAC_202302\\INV_ACUIFEROS_SHAC.shp\"\n",
    "\n",
    "OUTPUT_FOLDER = r\"\\assessment_of_wells_chile\\data\\DGA_vs_Census_Comparison\"\n",
    "\n",
    "COL_AREA_24 = 'AREA_C'\n",
    "COL_PERS_24 = 'n_per'\n",
    "COL_VIVIENDAS_24 = 'n_hog'\n",
    "COL_VIVIENDAS_TOTALES_24 = 'n_vp'\n",
    "\n",
    "COL_POZO_24 = 'n_fuente_agua_pozo'\n",
    "COL_RED_PUBLICA_24 = 'n_fuente_agua_publica'\n",
    "COL_CAMION_24 = 'n_fuente_agua_camion'\n",
    "COL_RIO_24 = 'n_fuente_agua_rio'\n",
    "\n",
    "COL_DGA_CAUDAL = 'Caudal_Ls'\n",
    "\n",
    "LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR = 31557.6\n",
    "\n",
    "WATER_SOURCES = {\n",
    "    'pozo': {\n",
    "        'name': 'Pozo o Noria',\n",
    "        'name_short': 'Pozo',\n",
    "        'col_2024': COL_POZO_24,\n",
    "        'description': 'Viviendas con origen del agua por pozo o noria (Wells)',\n",
    "        'priority': 1\n",
    "    },\n",
    "    'red_publica': {\n",
    "        'name': 'Red Publica',\n",
    "        'name_short': 'RedPublica',\n",
    "        'col_2024': COL_RED_PUBLICA_24,\n",
    "        'description': 'Viviendas con origen del agua por red publica (Public Network)',\n",
    "        'priority': 2\n",
    "    },\n",
    "    'camion': {\n",
    "        'name': 'Camion Aljibe',\n",
    "        'name_short': 'Camion',\n",
    "        'col_2024': COL_CAMION_24,\n",
    "        'description': 'Viviendas con origen del agua por camion aljibe (Water Truck)',\n",
    "        'priority': 3\n",
    "    },\n",
    "    'rio': {\n",
    "        'name': 'Rio/Vertiente/Estero',\n",
    "        'name_short': 'Rio',\n",
    "        'col_2024': COL_RIO_24,\n",
    "        'description': 'Viviendas con origen del agua por rio, vertiente, estero, canal, lago, etc. (River/Spring)',\n",
    "        'priority': 4\n",
    "    }\n",
    "}\n",
    "\n",
    "TARGET_CRS = \"EPSG:4326\"\n",
    "SHAC_BUFFER_DISTANCE = 200\n",
    "\n",
    "REFERENCE_LAYERS = [\n",
    "    {\n",
    "        'path': GDB_PATH,\n",
    "        'layer_name': 'CHL_Municipalities',\n",
    "        'prefix': 'Muni',\n",
    "        'name_col': 'NAME',\n",
    "        'code_col': 'Code_Muni',\n",
    "        'native_crs': 'EPSG:3857',\n",
    "        'is_gdb': True\n",
    "    },\n",
    "    {\n",
    "        'path': GDB_PATH,\n",
    "        'layer_name': 'CHL_Regions',\n",
    "        'prefix': 'Region',\n",
    "        'name_col': 'NAME',\n",
    "        'code_col': 'ID',\n",
    "        'native_crs': 'EPSG:3857',\n",
    "        'is_gdb': True\n",
    "    },\n",
    "    {\n",
    "        'path': SHP_CUENCAS,\n",
    "        'layer_name': None,\n",
    "        'prefix': 'Cuenca',\n",
    "        'name_col': 'NOM_CUEN',\n",
    "        'code_col': 'COD_CUEN',\n",
    "        'native_crs': 'EPSG:32719',\n",
    "        'is_gdb': False\n",
    "    },\n",
    "    {\n",
    "        'path': SHP_SHAC,\n",
    "        'layer_name': None,\n",
    "        'prefix': 'SHAC',\n",
    "        'name_col': 'SHAC',\n",
    "        'code_col': 'COD_SHAC',\n",
    "        'native_crs': 'EPSG:32719',\n",
    "        'is_gdb': False\n",
    "    }\n",
    "]\n",
    "\n",
    "def create_output_folder(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    subfolders = ['Shapefiles', 'Excel', 'Reports']\n",
    "    for f in subfolders:\n",
    "        Path(os.path.join(path, f)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_reference_layer(layer_config):\n",
    "    path = layer_config['path']\n",
    "    prefix = layer_config['prefix']\n",
    "    native_crs = layer_config['native_crs']\n",
    "    is_gdb = layer_config['is_gdb']\n",
    "    layer_name = layer_config.get('layer_name')\n",
    "    name_col = layer_config['name_col']\n",
    "    code_col = layer_config['code_col']\n",
    "    \n",
    "    try:\n",
    "        if is_gdb:\n",
    "            gdf = gpd.read_file(path, layer=layer_name)\n",
    "        else:\n",
    "            gdf = gpd.read_file(path)\n",
    "        \n",
    "        if gdf.crs is None:\n",
    "            gdf = gdf.set_crs(native_crs)\n",
    "        \n",
    "        if gdf.crs.to_string() != TARGET_CRS:\n",
    "            gdf = gdf.to_crs(TARGET_CRS)\n",
    "        \n",
    "        available_cols = gdf.columns.tolist()\n",
    "        \n",
    "        if name_col not in available_cols:\n",
    "            for col in available_cols:\n",
    "                if 'name' in col.lower() or 'nom' in col.lower():\n",
    "                    name_col = col\n",
    "                    break\n",
    "        \n",
    "        if code_col not in available_cols:\n",
    "            for col in available_cols:\n",
    "                if 'cod' in col.lower() or 'id' in col.lower():\n",
    "                    code_col = col\n",
    "                    break\n",
    "        \n",
    "        cols_to_keep = ['geometry']\n",
    "        if name_col in gdf.columns:\n",
    "            cols_to_keep.append(name_col)\n",
    "        if code_col in gdf.columns and code_col != name_col:\n",
    "            cols_to_keep.append(code_col)\n",
    "        \n",
    "        gdf = gdf[cols_to_keep].copy()\n",
    "        \n",
    "        rename_dict = {}\n",
    "        if name_col in gdf.columns:\n",
    "            rename_dict[name_col] = f'{prefix}_Name'\n",
    "        if code_col in gdf.columns and code_col != name_col:\n",
    "            rename_dict[code_col] = f'{prefix}_Code'\n",
    "        \n",
    "        gdf = gdf.rename(columns=rename_dict)\n",
    "        \n",
    "        return gdf, prefix\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR loading {prefix}: {str(e)}\")\n",
    "        return None, prefix\n",
    "\n",
    "def perform_spatial_join(gdf_points, gdf_polygons, prefix):\n",
    "    if gdf_points is None or len(gdf_points) == 0:\n",
    "        return gdf_points\n",
    "    \n",
    "    if gdf_polygons is None or len(gdf_polygons) == 0:\n",
    "        return gdf_points\n",
    "    \n",
    "    if gdf_points.crs != gdf_polygons.crs:\n",
    "        gdf_polygons = gdf_polygons.to_crs(gdf_points.crs)\n",
    "    \n",
    "    cols_to_drop = [col for col in gdf_points.columns if col.startswith('index_')]\n",
    "    if cols_to_drop:\n",
    "        gdf_points = gdf_points.drop(columns=cols_to_drop)\n",
    "    \n",
    "    gdf_points = gdf_points.reset_index(drop=True)\n",
    "    gdf_polygons = gdf_polygons.reset_index(drop=True)\n",
    "    \n",
    "    try:\n",
    "        gdf_joined = gpd.sjoin(\n",
    "            gdf_points, \n",
    "            gdf_polygons, \n",
    "            how='left', \n",
    "            predicate='within'\n",
    "        )\n",
    "        \n",
    "        cols_to_drop = [col for col in gdf_joined.columns if col.startswith('index_')]\n",
    "        if cols_to_drop:\n",
    "            gdf_joined = gdf_joined.drop(columns=cols_to_drop)\n",
    "        \n",
    "        gdf_joined = gdf_joined.reset_index(drop=True)\n",
    "        \n",
    "        return gdf_joined\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR in spatial join: {str(e)}\")\n",
    "        return gdf_points\n",
    "\n",
    "def get_centroid_gdf(gdf):\n",
    "    gdf_copy = gdf.copy()\n",
    "    gdf_copy['_original_geometry'] = gdf_copy.geometry\n",
    "    gdf_copy['geometry'] = gdf_copy.geometry.centroid\n",
    "    return gdf_copy\n",
    "\n",
    "def restore_original_geometry(gdf):\n",
    "    if '_original_geometry' in gdf.columns:\n",
    "        gdf['geometry'] = gdf['_original_geometry']\n",
    "        gdf = gdf.drop(columns=['_original_geometry'])\n",
    "    return gdf\n",
    "\n",
    "def classify_delta(delta_value, census_wells, dga_rights):\n",
    "    if census_wells == 0 and dga_rights == 0:\n",
    "        return \"No_Wells_No_Rights\"\n",
    "    elif delta_value > 0:\n",
    "        return \"DGA_Higher_Than_Census\"\n",
    "    elif delta_value < 0:\n",
    "        return \"Census_Higher_Than_DGA\"\n",
    "    else:\n",
    "        return \"DGA_Equals_Census\"\n",
    "\n",
    "def classify_delta_detailed(delta_value, census_wells, dga_rights):\n",
    "    if census_wells == 0 and dga_rights == 0:\n",
    "        return \"No data - Neither census wells nor DGA rights\"\n",
    "    elif census_wells > 0 and dga_rights == 0:\n",
    "        return \"Census only - Potential unregistered wells\"\n",
    "    elif census_wells == 0 and dga_rights > 0:\n",
    "        return \"DGA only - Rights exist but no census wells\"\n",
    "    elif delta_value > 50:\n",
    "        return \"DGA >> Census - Significant excess of water rights\"\n",
    "    elif delta_value > 10:\n",
    "        return \"DGA > Census - Moderate excess of water rights\"\n",
    "    elif delta_value > 0:\n",
    "        return \"DGA slightly > Census\"\n",
    "    elif delta_value < -50:\n",
    "        return \"Census >> DGA - Many potential unregistered wells\"\n",
    "    elif delta_value < -10:\n",
    "        return \"Census > DGA - Moderate unregistered wells\"\n",
    "    elif delta_value < 0:\n",
    "        return \"Census slightly > DGA - Few potential unregistered\"\n",
    "    else:\n",
    "        return \"DGA equals Census - Full registration\"\n",
    "\n",
    "def classify_primary_water_source(row):\n",
    "    sources = {\n",
    "        'RedPublica': row.get('WS_RedPublica', 0),\n",
    "        'Pozo': row.get('WS_Pozo', 0),\n",
    "        'Camion': row.get('WS_Camion', 0),\n",
    "        'Rio': row.get('WS_Rio', 0)\n",
    "    }\n",
    "    \n",
    "    total = sum(sources.values())\n",
    "    if total == 0:\n",
    "        return 'No_Data', 0\n",
    "    \n",
    "    primary = max(sources, key=sources.get)\n",
    "    pct = (sources[primary] / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    return primary, round(pct, 1)\n",
    "\n",
    "def buffer_shac_for_spatial_join(gdf_shac, buffer_distance_meters=200):\n",
    "    original_crs = gdf_shac.crs\n",
    "    gdf_projected = gdf_shac.to_crs('EPSG:32719')\n",
    "    gdf_buffered = gdf_projected.copy()\n",
    "    gdf_buffered['geometry'] = gdf_projected.geometry.buffer(buffer_distance_meters)\n",
    "    gdf_buffered = gdf_buffered.to_crs(original_crs)\n",
    "    return gdf_buffered\n",
    "\n",
    "def convert_ls_to_m3y(caudal_ls):\n",
    "    return caudal_ls * LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"DGA WATER RIGHTS vs CENSUS 2024 WELLS COMPARISON ANALYSIS\")\n",
    "    print(\"Including All Water Sources: Red Publica, Pozo, Camion, Rio\")\n",
    "    print(\"Including DGA Flow Rates (Caudal) Aggregation\")\n",
    "    print(\"Delta Calculation: DGA Water Rights - Census Wells\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    create_output_folder(OUTPUT_FOLDER)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 1: Loading DGA Water Rights data...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    try:\n",
    "        df_dga = pd.read_csv(DGA_CSV_PATH)\n",
    "        print(f\"   Loaded {len(df_dga)} DGA water rights records from CSV\")\n",
    "    except Exception as e:\n",
    "        print(f\"   CSV load failed: {e}\")\n",
    "        try:\n",
    "            excel_path = DGA_CSV_PATH.replace('.csv', '.xlsx')\n",
    "            df_dga = pd.read_excel(excel_path)\n",
    "            print(f\"   Loaded {len(df_dga)} DGA water rights records from Excel\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   ERROR loading DGA data: {e2}\")\n",
    "            return\n",
    "    \n",
    "    df_dga = df_dga[df_dga['lat_wgs84'].notna() & df_dga['lon_wgs84'].notna()].copy()\n",
    "    df_dga = df_dga[(df_dga['lat_wgs84'] != 0) & (df_dga['lon_wgs84'] != 0)].copy()\n",
    "    print(f\"   Valid DGA records with coordinates: {len(df_dga)}\")\n",
    "    \n",
    "    if COL_DGA_CAUDAL in df_dga.columns:\n",
    "        df_dga['Caudal_Ls'] = pd.to_numeric(df_dga[COL_DGA_CAUDAL], errors='coerce').fillna(0)\n",
    "        total_caudal_ls = df_dga['Caudal_Ls'].sum()\n",
    "        total_caudal_m3y = convert_ls_to_m3y(total_caudal_ls)\n",
    "        print(f\"   Total DGA Flow Rate (Caudal):\")\n",
    "        print(f\"      - {total_caudal_ls:,.2f} L/s\")\n",
    "        print(f\"      - {total_caudal_m3y:,.2f} m³/year\")\n",
    "        print(f\"   Average Caudal per right: {df_dga['Caudal_Ls'].mean():.2f} L/s\")\n",
    "        print(f\"   Max Caudal: {df_dga['Caudal_Ls'].max():.2f} L/s\")\n",
    "        print(f\"   Min Caudal (non-zero): {df_dga[df_dga['Caudal_Ls'] > 0]['Caudal_Ls'].min():.4f} L/s\")\n",
    "    else:\n",
    "        print(f\"   WARNING: Column '{COL_DGA_CAUDAL}' not found in DGA data!\")\n",
    "        df_dga['Caudal_Ls'] = 0\n",
    "    \n",
    "    gdf_dga = gpd.GeoDataFrame(\n",
    "        df_dga[['lat_wgs84', 'lon_wgs84', 'Caudal_Ls']],\n",
    "        geometry=gpd.points_from_xy(df_dga['lon_wgs84'], df_dga['lat_wgs84']),\n",
    "        crs=TARGET_CRS\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 2: Loading Census 2024 data...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf_census = gpd.read_file(GDB_PATH, layer=LAYER_CENSO_2024)\n",
    "    original_crs = gdf_census.crs\n",
    "    if gdf_census.crs != TARGET_CRS:\n",
    "        gdf_census = gdf_census.to_crs(TARGET_CRS)\n",
    "    print(f\"   Loaded {len(gdf_census)} census blocks\")\n",
    "    print(f\"   Original CRS: {original_crs}, Converted to: {TARGET_CRS}\")\n",
    "    \n",
    "    print(\"\\n   Processing Census 2024 columns...\")\n",
    "    \n",
    "    print(\"\\n   --- Water Sources ---\")\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_orig = src_info['col_2024']\n",
    "        col_new = f\"WS_{src_info['name_short']}\"\n",
    "        \n",
    "        if col_orig in gdf_census.columns:\n",
    "            gdf_census[col_new] = pd.to_numeric(gdf_census[col_orig], errors='coerce').fillna(0).astype(int)\n",
    "            total = gdf_census[col_new].sum()\n",
    "            print(f\"   - {src_info['name']} ('{col_orig}'): {total:,} households\")\n",
    "        else:\n",
    "            gdf_census[col_new] = 0\n",
    "            print(f\"   - WARNING: Column '{col_orig}' not found for {src_info['name']}\")\n",
    "    \n",
    "    gdf_census['Census_Wells'] = gdf_census['WS_Pozo']\n",
    "    \n",
    "    gdf_census['WS_Total'] = (\n",
    "        gdf_census['WS_RedPublica'] + \n",
    "        gdf_census['WS_Pozo'] + \n",
    "        gdf_census['WS_Camion'] + \n",
    "        gdf_census['WS_Rio']\n",
    "    )\n",
    "    \n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_ws = f\"WS_{src_info['name_short']}\"\n",
    "        col_pct = f\"Pct_{src_info['name_short']}\"\n",
    "        gdf_census[col_pct] = np.where(\n",
    "            gdf_census['WS_Total'] > 0,\n",
    "            (gdf_census[col_ws] / gdf_census['WS_Total'] * 100).round(2),\n",
    "            0\n",
    "        )\n",
    "    \n",
    "    primary_sources = gdf_census.apply(classify_primary_water_source, axis=1)\n",
    "    gdf_census['Primary_WS'] = [x[0] for x in primary_sources]\n",
    "    gdf_census['Primary_WS_Pct'] = [x[1] for x in primary_sources]\n",
    "    \n",
    "    print(f\"\\n   Primary Water Source Distribution:\")\n",
    "    primary_counts = gdf_census['Primary_WS'].value_counts()\n",
    "    for src, count in primary_counts.items():\n",
    "        pct = count / len(gdf_census) * 100\n",
    "        print(f\"      {src}: {count:,} blocks ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n   --- Demographics ---\")\n",
    "    \n",
    "    if COL_PERS_24 in gdf_census.columns:\n",
    "        gdf_census['Personas_24'] = pd.to_numeric(gdf_census[COL_PERS_24], errors='coerce').fillna(0).astype(int)\n",
    "        print(f\"   - Population: {gdf_census['Personas_24'].sum():,}\")\n",
    "    else:\n",
    "        gdf_census['Personas_24'] = 0\n",
    "    \n",
    "    if COL_VIVIENDAS_24 in gdf_census.columns:\n",
    "        gdf_census['Viviendas_24'] = pd.to_numeric(gdf_census[COL_VIVIENDAS_24], errors='coerce').fillna(0).astype(int)\n",
    "        print(f\"   - Occupied Households: {gdf_census['Viviendas_24'].sum():,}\")\n",
    "    else:\n",
    "        gdf_census['Viviendas_24'] = 0\n",
    "    \n",
    "    if COL_VIVIENDAS_TOTALES_24 in gdf_census.columns:\n",
    "        gdf_census['Viv_Total_24'] = pd.to_numeric(gdf_census[COL_VIVIENDAS_TOTALES_24], errors='coerce').fillna(0).astype(int)\n",
    "        print(f\"   - Total Households: {gdf_census['Viv_Total_24'].sum():,}\")\n",
    "    else:\n",
    "        gdf_census['Viv_Total_24'] = 0\n",
    "    \n",
    "    if COL_AREA_24 in gdf_census.columns:\n",
    "        gdf_census['Is_Rural'] = np.where(\n",
    "            gdf_census[COL_AREA_24].astype(str).str.upper().str.strip() == 'RURAL', 1, 0\n",
    "        )\n",
    "        gdf_census['Area_Type'] = np.where(gdf_census['Is_Rural'] == 1, 'Rural', 'Urban')\n",
    "        print(f\"   - Rural blocks: {gdf_census['Is_Rural'].sum():,}\")\n",
    "        print(f\"   - Urban blocks: {(gdf_census['Is_Rural'] == 0).sum():,}\")\n",
    "    else:\n",
    "        gdf_census['Is_Rural'] = 0\n",
    "        gdf_census['Area_Type'] = 'Unknown'\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 3: Loading reference layers for spatial joins...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    reference_gdfs = {}\n",
    "    for layer_config in REFERENCE_LAYERS:\n",
    "        gdf_ref, prefix = load_reference_layer(layer_config)\n",
    "        if gdf_ref is not None:\n",
    "            reference_gdfs[prefix] = gdf_ref\n",
    "            print(f\"   Loaded {prefix}: {len(gdf_ref)} features\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 4: Counting DGA water rights and summing Caudal per census block...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    if gdf_dga.crs != gdf_census.crs:\n",
    "        gdf_dga = gdf_dga.to_crs(gdf_census.crs)\n",
    "    \n",
    "    gdf_census = gdf_census.reset_index(drop=True)\n",
    "    gdf_census['block_idx'] = gdf_census.index\n",
    "    \n",
    "    print(\"   Performing spatial join (DGA points -> Census blocks)...\")\n",
    "    gdf_dga_joined = gpd.sjoin(\n",
    "        gdf_dga[['geometry', 'Caudal_Ls']], \n",
    "        gdf_census[['geometry', 'block_idx']], \n",
    "        how='left', \n",
    "        predicate='within'\n",
    "    )\n",
    "    \n",
    "    print(\"   Aggregating DGA counts and Caudal per census block...\")\n",
    "    dga_aggregates = gdf_dga_joined.groupby('block_idx').agg(\n",
    "        DGA_WaterRights=('block_idx', 'count'),\n",
    "        DGA_Caudal_Ls=('Caudal_Ls', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    dga_stats = gdf_dga_joined.groupby('block_idx').agg(\n",
    "        DGA_Caudal_Mean=('Caudal_Ls', 'mean'),\n",
    "        DGA_Caudal_Max=('Caudal_Ls', 'max'),\n",
    "        DGA_Caudal_Min=('Caudal_Ls', 'min'),\n",
    "        DGA_Caudal_Median=('Caudal_Ls', 'median')\n",
    "    ).reset_index()\n",
    "    \n",
    "    dga_aggregates = dga_aggregates.merge(dga_stats, on='block_idx', how='left')\n",
    "    \n",
    "    gdf_census = gdf_census.merge(dga_aggregates, on='block_idx', how='left')\n",
    "    \n",
    "    gdf_census['DGA_WaterRights'] = gdf_census['DGA_WaterRights'].fillna(0).astype(int)\n",
    "    gdf_census['DGA_Caudal_Ls'] = gdf_census['DGA_Caudal_Ls'].fillna(0).round(4)\n",
    "    gdf_census['DGA_Caudal_Mean'] = gdf_census['DGA_Caudal_Mean'].fillna(0).round(4)\n",
    "    gdf_census['DGA_Caudal_Max'] = gdf_census['DGA_Caudal_Max'].fillna(0).round(4)\n",
    "    gdf_census['DGA_Caudal_Min'] = gdf_census['DGA_Caudal_Min'].fillna(0).round(4)\n",
    "    gdf_census['DGA_Caudal_Median'] = gdf_census['DGA_Caudal_Median'].fillna(0).round(4)\n",
    "    \n",
    "    gdf_census['DGA_Caudal_m3y'] = (gdf_census['DGA_Caudal_Ls'] * LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR).round(2)\n",
    "    gdf_census['DGA_Caudal_Mean_m3y'] = (gdf_census['DGA_Caudal_Mean'] * LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR).round(2)\n",
    "    gdf_census['DGA_Caudal_Max_m3y'] = (gdf_census['DGA_Caudal_Max'] * LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR).round(2)\n",
    "    gdf_census['DGA_Caudal_Min_m3y'] = (gdf_census['DGA_Caudal_Min'] * LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR).round(2)\n",
    "    gdf_census['DGA_Caudal_Median_m3y'] = (gdf_census['DGA_Caudal_Median'] * LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR).round(2)\n",
    "    \n",
    "    print(f\"\\n   === DGA SPATIAL JOIN RESULTS ===\")\n",
    "    print(f\"   DGA points successfully joined: {gdf_dga_joined['block_idx'].notna().sum():,}\")\n",
    "    print(f\"   DGA points outside census blocks: {gdf_dga_joined['block_idx'].isna().sum():,}\")\n",
    "    print(f\"   Census blocks with DGA rights: {(gdf_census['DGA_WaterRights'] > 0).sum():,}\")\n",
    "    print(f\"   Total DGA rights assigned to blocks: {gdf_census['DGA_WaterRights'].sum():,}\")\n",
    "    \n",
    "    print(f\"\\n   === DGA CAUDAL SUMMARY ===\")\n",
    "    print(f\"   Total Caudal in census blocks: {gdf_census['DGA_Caudal_Ls'].sum():,.2f} L/s\")\n",
    "    print(f\"   Total Caudal in census blocks: {gdf_census['DGA_Caudal_m3y'].sum():,.2f} m³/year\")\n",
    "    print(f\"   Blocks with Caudal > 0: {(gdf_census['DGA_Caudal_Ls'] > 0).sum():,}\")\n",
    "    print(f\"   Max Caudal in single block: {gdf_census['DGA_Caudal_Ls'].max():,.2f} L/s\")\n",
    "    print(f\"   Average Caudal per block (with rights): {gdf_census[gdf_census['DGA_Caudal_Ls'] > 0]['DGA_Caudal_Ls'].mean():,.2f} L/s\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 5: Calculating Delta (DGA - Census) and Classification...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf_census['Delta_DGA_Census'] = gdf_census['DGA_WaterRights'] - gdf_census['Census_Wells']\n",
    "    \n",
    "    gdf_census['Delta_Census_DGA'] = gdf_census['Census_Wells'] - gdf_census['DGA_WaterRights']\n",
    "    \n",
    "    gdf_census['Comparison'] = gdf_census.apply(\n",
    "        lambda row: classify_delta(row['Delta_DGA_Census'], row['Census_Wells'], row['DGA_WaterRights']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    gdf_census['Comparison_Detail'] = gdf_census.apply(\n",
    "        lambda row: classify_delta_detailed(row['Delta_DGA_Census'], row['Census_Wells'], row['DGA_WaterRights']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    gdf_census['Caudal_per_CensusWell'] = np.where(\n",
    "        gdf_census['Census_Wells'] > 0,\n",
    "        (gdf_census['DGA_Caudal_Ls'] / gdf_census['Census_Wells']).round(4),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n   === DELTA SUMMARY (DGA - Census) ===\")\n",
    "    print(f\"   Total Census Wells (Pozo): {gdf_census['Census_Wells'].sum():,}\")\n",
    "    print(f\"   Total DGA Rights: {gdf_census['DGA_WaterRights'].sum():,}\")\n",
    "    print(f\"   Total Delta: {gdf_census['Delta_DGA_Census'].sum():,}\")\n",
    "    \n",
    "    print(f\"\\n   === WATER SOURCES SUMMARY ===\")\n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_ws = f\"WS_{src_info['name_short']}\"\n",
    "        total = gdf_census[col_ws].sum()\n",
    "        pct = total / gdf_census['WS_Total'].sum() * 100 if gdf_census['WS_Total'].sum() > 0 else 0\n",
    "        print(f\"   - {src_info['name']}: {total:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n   === COMPARISON CLASSIFICATION ===\")\n",
    "    comparison_counts = gdf_census['Comparison'].value_counts()\n",
    "    for comp_type, count in comparison_counts.items():\n",
    "        pct = count / len(gdf_census) * 100\n",
    "        print(f\"   - {comp_type}: {count:,} blocks ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 6: Spatial joins with reference layers...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf_census_centroids = get_centroid_gdf(gdf_census)\n",
    "    \n",
    "    for prefix, ref_gdf in reference_gdfs.items():\n",
    "        print(f\"   Joining with {prefix}...\")\n",
    "        if prefix == 'SHAC':\n",
    "            ref_gdf_buffered = buffer_shac_for_spatial_join(ref_gdf, SHAC_BUFFER_DISTANCE)\n",
    "            gdf_census_centroids = perform_spatial_join(gdf_census_centroids, ref_gdf_buffered, prefix)\n",
    "        else:\n",
    "            gdf_census_centroids = perform_spatial_join(gdf_census_centroids, ref_gdf, prefix)\n",
    "    \n",
    "    gdf_census_joined = restore_original_geometry(gdf_census_centroids)\n",
    "    \n",
    "    centroids = gdf_census_joined.geometry.centroid\n",
    "    gdf_census_joined['Centroid_Lon'] = centroids.x\n",
    "    gdf_census_joined['Centroid_Lat'] = centroids.y\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 7: Preparing output columns...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    output_cols = [\n",
    "        'Census_Wells',\n",
    "        'DGA_WaterRights', \n",
    "        'Delta_DGA_Census',\n",
    "        'Delta_Census_DGA',\n",
    "        'Comparison',\n",
    "        'Comparison_Detail',\n",
    "        \n",
    "        'DGA_Caudal_Ls',\n",
    "        'DGA_Caudal_Mean',\n",
    "        'DGA_Caudal_Median',\n",
    "        'DGA_Caudal_Max',\n",
    "        'DGA_Caudal_Min',\n",
    "        \n",
    "        'DGA_Caudal_m3y',\n",
    "        'DGA_Caudal_Mean_m3y',\n",
    "        'DGA_Caudal_Median_m3y',\n",
    "        'DGA_Caudal_Max_m3y',\n",
    "        'DGA_Caudal_Min_m3y',\n",
    "        \n",
    "        'Caudal_per_CensusWell',\n",
    "        \n",
    "        'WS_RedPublica',\n",
    "        'WS_Pozo',\n",
    "        'WS_Camion',\n",
    "        'WS_Rio',\n",
    "        'WS_Total',\n",
    "        \n",
    "        'Pct_RedPublica',\n",
    "        'Pct_Pozo',\n",
    "        'Pct_Camion',\n",
    "        'Pct_Rio',\n",
    "        \n",
    "        'Primary_WS',\n",
    "        'Primary_WS_Pct',\n",
    "        \n",
    "        'Personas_24',\n",
    "        'Viviendas_24',\n",
    "        'Viv_Total_24',\n",
    "        'Area_Type',\n",
    "        'Is_Rural',\n",
    "        \n",
    "        'Muni_Name', 'Muni_Code',\n",
    "        'Region_Name', 'Region_Code',\n",
    "        'Cuenca_Name', 'Cuenca_Code',\n",
    "        'SHAC_Name', 'SHAC_Code',\n",
    "        \n",
    "        'Centroid_Lon', 'Centroid_Lat',\n",
    "        \n",
    "        'geometry'\n",
    "    ]\n",
    "    \n",
    "    available_cols = [c for c in output_cols if c in gdf_census_joined.columns]\n",
    "    print(f\"   Output columns: {len(available_cols)}\")\n",
    "    \n",
    "    gdf_output = gdf_census_joined[available_cols].copy()\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 8: Saving Shapefile...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    shp_rename = {\n",
    "        'Census_Wells': 'Cens_Well',\n",
    "        'DGA_WaterRights': 'DGA_Rights',\n",
    "        'Delta_DGA_Census': 'Delta_DGA',\n",
    "        'Delta_Census_DGA': 'Delta_Cens',\n",
    "        'Comparison': 'Comparison',\n",
    "        'Comparison_Detail': 'Comp_Det',\n",
    "        'DGA_Caudal_Ls': 'DGA_Q_Ls',\n",
    "        'DGA_Caudal_Mean': 'DGA_Q_Mean',\n",
    "        'DGA_Caudal_Median': 'DGA_Q_Med',\n",
    "        'DGA_Caudal_Max': 'DGA_Q_Max',\n",
    "        'DGA_Caudal_Min': 'DGA_Q_Min',\n",
    "        'DGA_Caudal_m3y': 'DGA_Q_m3y',\n",
    "        'DGA_Caudal_Mean_m3y': 'Q_Mean_m3y',\n",
    "        'DGA_Caudal_Median_m3y': 'Q_Med_m3y',\n",
    "        'DGA_Caudal_Max_m3y': 'Q_Max_m3y',\n",
    "        'DGA_Caudal_Min_m3y': 'Q_Min_m3y',\n",
    "        \n",
    "        'Caudal_per_CensusWell': 'Q_perWell',\n",
    "        'WS_RedPublica': 'WS_RedPub',\n",
    "        'WS_Pozo': 'WS_Pozo',\n",
    "        'WS_Camion': 'WS_Camion',\n",
    "        'WS_Rio': 'WS_Rio',\n",
    "        'WS_Total': 'WS_Total',\n",
    "        'Pct_RedPublica': 'Pct_RedPub',\n",
    "        'Pct_Pozo': 'Pct_Pozo',\n",
    "        'Pct_Camion': 'Pct_Camion',\n",
    "        'Pct_Rio': 'Pct_Rio',\n",
    "        'Primary_WS': 'Prim_WS',\n",
    "        'Primary_WS_Pct': 'Prim_WS_Pc',\n",
    "        'Personas_24': 'Personas',\n",
    "        'Viviendas_24': 'Viviendas',\n",
    "        'Viv_Total_24': 'Viv_Total',\n",
    "        'Area_Type': 'Area_Type',\n",
    "        'Is_Rural': 'Is_Rural',\n",
    "        'Muni_Name': 'Muni_Name',\n",
    "        'Muni_Code': 'Muni_Code',\n",
    "        'Region_Name': 'Reg_Name',\n",
    "        'Region_Code': 'Reg_Code',\n",
    "        'Cuenca_Name': 'Cuen_Name',\n",
    "        'Cuenca_Code': 'Cuen_Code',\n",
    "        'SHAC_Name': 'SHAC_Name',\n",
    "        'SHAC_Code': 'SHAC_Code',\n",
    "        'Centroid_Lon': 'Cent_Lon',\n",
    "        'Centroid_Lat': 'Cent_Lat'\n",
    "    }\n",
    "    \n",
    "    gdf_shp = gdf_output.copy()\n",
    "    gdf_shp = gdf_shp.rename(columns={k: v for k, v in shp_rename.items() if k in gdf_shp.columns})\n",
    "    \n",
    "    shp_path = os.path.join(OUTPUT_FOLDER, 'Shapefiles', 'Census2024_vs_DGA_Comparison.shp')\n",
    "    gdf_shp.to_file(shp_path, driver='ESRI Shapefile', encoding='utf-8')\n",
    "    print(f\"   Saved: {shp_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 9: Saving Excel files...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    df_block = gdf_output.drop(columns='geometry').copy()\n",
    "    block_excel_path = os.path.join(OUTPUT_FOLDER, 'Excel', 'Census2024_vs_DGA_Block_Level.xlsx')\n",
    "    df_block.to_excel(block_excel_path, index=False)\n",
    "    print(f\"   Saved: {block_excel_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 10: Calculating aggregated statistics at multiple levels...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    aggregation_levels = [\n",
    "        ('Region', 'Region_Name', 'Region_Code'),\n",
    "        ('Municipality', 'Muni_Name', 'Muni_Code'),\n",
    "        ('Basin', 'Cuenca_Name', 'Cuenca_Code'),\n",
    "        ('SHAC', 'SHAC_Name', 'SHAC_Code')\n",
    "    ]\n",
    "    \n",
    "    all_stats = {}\n",
    "    \n",
    "    for level_name, name_col, code_col in aggregation_levels:\n",
    "        if name_col not in gdf_output.columns:\n",
    "            print(f\"   Skipping {level_name} - column '{name_col}' not available\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   Aggregating at {level_name} level...\")\n",
    "        \n",
    "        gdf_level = gdf_output[gdf_output[name_col].notna()].copy()\n",
    "        \n",
    "        if len(gdf_level) == 0:\n",
    "            print(f\"      No valid data for {level_name}\")\n",
    "            continue\n",
    "        \n",
    "        agg_dict = {\n",
    "            'Census_Wells': 'sum',\n",
    "            'DGA_WaterRights': 'sum',\n",
    "            'Delta_DGA_Census': 'sum',\n",
    "            'Delta_Census_DGA': 'sum',\n",
    "            'DGA_Caudal_Ls': 'sum',\n",
    "            'DGA_Caudal_m3y': 'sum',\n",
    "            'WS_RedPublica': 'sum',\n",
    "            'WS_Pozo': 'sum',\n",
    "            'WS_Camion': 'sum',\n",
    "            'WS_Rio': 'sum',\n",
    "            'WS_Total': 'sum',\n",
    "            'Personas_24': 'sum',\n",
    "            'Viviendas_24': 'sum',\n",
    "            'Viv_Total_24': 'sum',\n",
    "            'Is_Rural': 'sum'\n",
    "        }\n",
    "        \n",
    "        agg_dict = {k: v for k, v in agg_dict.items() if k in gdf_level.columns}\n",
    "        \n",
    "        groupby_cols = [name_col]\n",
    "        if code_col in gdf_level.columns:\n",
    "            groupby_cols.append(code_col)\n",
    "        \n",
    "        stats = gdf_level.groupby(groupby_cols, dropna=False).agg(agg_dict).reset_index()\n",
    "        \n",
    "        block_counts = gdf_level.groupby(groupby_cols, dropna=False).size().reset_index(name='N_Blocks')\n",
    "        stats = stats.merge(block_counts, on=groupby_cols)\n",
    "        \n",
    "        caudal_stats = gdf_level.groupby(groupby_cols, dropna=False).agg(\n",
    "            DGA_Caudal_Mean=('DGA_Caudal_Ls', 'mean'),\n",
    "            DGA_Caudal_Max=('DGA_Caudal_Ls', 'max')\n",
    "        ).reset_index()\n",
    "        stats = stats.merge(caudal_stats, on=groupby_cols, how='left')\n",
    "        stats['DGA_Caudal_Mean'] = stats['DGA_Caudal_Mean'].round(4)\n",
    "        stats['DGA_Caudal_Max'] = stats['DGA_Caudal_Max'].round(4)\n",
    "        \n",
    "        for comp_type in ['Census_Higher_Than_DGA', 'DGA_Higher_Than_Census', 'DGA_Equals_Census', 'No_Wells_No_Rights']:\n",
    "            comp_counts = gdf_level.groupby(groupby_cols, dropna=False).apply(\n",
    "                lambda x: (x['Comparison'] == comp_type).sum()\n",
    "            ).reset_index(name=f'N_{comp_type.replace(\"_\", \"\")}')\n",
    "            stats = stats.merge(comp_counts, on=groupby_cols, how='left')\n",
    "        \n",
    "        for ws_type in ['RedPublica', 'Pozo', 'Camion', 'Rio', 'No_Data']:\n",
    "            ws_counts = gdf_level.groupby(groupby_cols, dropna=False).apply(\n",
    "                lambda x: (x['Primary_WS'] == ws_type).sum()\n",
    "            ).reset_index(name=f'N_Primary_{ws_type}')\n",
    "            stats = stats.merge(ws_counts, on=groupby_cols, how='left')\n",
    "        \n",
    "        for src_key, src_info in WATER_SOURCES.items():\n",
    "            col_ws = f\"WS_{src_info['name_short']}\"\n",
    "            col_pct = f\"Agg_Pct_{src_info['name_short']}\"\n",
    "            if col_ws in stats.columns and 'WS_Total' in stats.columns:\n",
    "                stats[col_pct] = np.where(\n",
    "                    stats['WS_Total'] > 0,\n",
    "                    (stats[col_ws] / stats['WS_Total'] * 100).round(2),\n",
    "                    0\n",
    "                )\n",
    "        \n",
    "        stats['Pct_CensusWells_WithDGA'] = np.where(\n",
    "            stats['Census_Wells'] > 0,\n",
    "            (stats['DGA_WaterRights'] / stats['Census_Wells'] * 100).round(2),\n",
    "            np.nan\n",
    "        )\n",
    "        \n",
    "        stats['Pct_DGA_WithCensusWells'] = np.where(\n",
    "            stats['DGA_WaterRights'] > 0,\n",
    "            (stats['Census_Wells'] / stats['DGA_WaterRights'] * 100).round(2),\n",
    "            np.nan\n",
    "        )\n",
    "        \n",
    "        stats['Agg_Caudal_per_CensusWell'] = np.where(\n",
    "            stats['Census_Wells'] > 0,\n",
    "            (stats['DGA_Caudal_Ls'] / stats['Census_Wells']).round(4),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        stats['Agg_Caudal_per_DGARight'] = np.where(\n",
    "            stats['DGA_WaterRights'] > 0,\n",
    "            (stats['DGA_Caudal_Ls'] / stats['DGA_WaterRights']).round(4),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        stats['Agg_Comparison'] = np.where(\n",
    "            stats['Delta_DGA_Census'] > 0, 'DGA_Higher',\n",
    "            np.where(stats['Delta_DGA_Census'] < 0, 'Census_Higher', 'Equal')\n",
    "        )\n",
    "        \n",
    "        def get_dominant_ws(row):\n",
    "            sources = {\n",
    "                'RedPublica': row.get('WS_RedPublica', 0),\n",
    "                'Pozo': row.get('WS_Pozo', 0),\n",
    "                'Camion': row.get('WS_Camion', 0),\n",
    "                'Rio': row.get('WS_Rio', 0)\n",
    "            }\n",
    "            total = sum(sources.values())\n",
    "            if total == 0:\n",
    "                return 'No_Data'\n",
    "            return max(sources, key=sources.get)\n",
    "        \n",
    "        stats['Dominant_WS'] = stats.apply(get_dominant_ws, axis=1)\n",
    "        \n",
    "        stats['N_Urban_Blocks'] = stats['N_Blocks'] - stats['Is_Rural']\n",
    "        stats = stats.rename(columns={'Is_Rural': 'N_Rural_Blocks'})\n",
    "        \n",
    "        stats = stats.sort_values('Delta_Census_DGA', ascending=False)\n",
    "        \n",
    "        all_stats[level_name] = stats\n",
    "        print(f\"      {level_name}: {len(stats)} units analyzed\")\n",
    "        print(f\"         Total Caudal: {stats['DGA_Caudal_Ls'].sum():,.2f} L/s = {stats['DGA_Caudal_m3y'].sum():,.2f} m³/year\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 11: Saving aggregated Excel files...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    combined_path = os.path.join(OUTPUT_FOLDER, 'Excel', 'Census2024_vs_DGA_All_Levels.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(combined_path, engine='openpyxl') as writer:\n",
    "        \n",
    "        total_census = gdf_output['Census_Wells'].sum()\n",
    "        total_dga = gdf_output['DGA_WaterRights'].sum()\n",
    "        total_caudal_ls = gdf_output['DGA_Caudal_Ls'].sum()\n",
    "        total_caudal_m3y = gdf_output['DGA_Caudal_m3y'].sum()\n",
    "        \n",
    "        ws_totals = {src_info['name']: gdf_output[f\"WS_{src_info['name_short']}\"].sum() \n",
    "                     for src_key, src_info in WATER_SOURCES.items()}\n",
    "        ws_grand_total = sum(ws_totals.values())\n",
    "        \n",
    "        national_summary = pd.DataFrame({\n",
    "            'Metric': [\n",
    "                'Total Census Blocks Analyzed',\n",
    "                'Total Census Wells (Households with Pozo)',\n",
    "                'Total DGA Water Rights (in census blocks)',\n",
    "                'Delta (DGA - Census)',\n",
    "                'Delta (Census - DGA)',\n",
    "                'DGA Coverage Rate (DGA/Census %)',\n",
    "                '',\n",
    "                '--- DGA FLOW RATES (CAUDAL) ---',\n",
    "                'Total Caudal (L/s)',\n",
    "                'Total Caudal (m³/year)',\n",
    "                'Average Caudal per DGA Right (L/s)',\n",
    "                'Average Caudal per Census Well (L/s)',\n",
    "                'Max Caudal in single block (L/s)',\n",
    "                'Blocks with Caudal > 0',\n",
    "                '',\n",
    "                '--- WATER SOURCES ---',\n",
    "                'Red Publica (Public Network)',\n",
    "                'Pozo o Noria (Wells)',\n",
    "                'Camion Aljibe (Water Truck)',\n",
    "                'Rio/Vertiente/Estero (River/Spring)',\n",
    "                'Total Water Source Records',\n",
    "                '',\n",
    "                '--- WATER SOURCE PERCENTAGES ---',\n",
    "                '% Red Publica',\n",
    "                '% Pozo',\n",
    "                '% Camion',\n",
    "                '% Rio',\n",
    "                '',\n",
    "                '--- COMPARISON CLASSIFICATION ---',\n",
    "                'Blocks: Census > DGA (potential unregistered)',\n",
    "                'Blocks: DGA > Census', \n",
    "                'Blocks: DGA = Census',\n",
    "                'Blocks: No Wells, No Rights',\n",
    "                '',\n",
    "                '--- DEMOGRAPHICS ---',\n",
    "                'Total Rural Blocks',\n",
    "                'Total Urban Blocks',\n",
    "                'Total Population',\n",
    "                'Total Households (Occupied)',\n",
    "                'Total Households (All)'\n",
    "            ],\n",
    "            'Value': [\n",
    "                len(gdf_output),\n",
    "                total_census,\n",
    "                total_dga,\n",
    "                total_dga - total_census,\n",
    "                total_census - total_dga,\n",
    "                (total_dga / total_census * 100) if total_census > 0 else 0,\n",
    "                '',\n",
    "                '',\n",
    "                total_caudal_ls,\n",
    "                total_caudal_m3y,\n",
    "                (total_caudal_ls / total_dga) if total_dga > 0 else 0,\n",
    "                (total_caudal_ls / total_census) if total_census > 0 else 0,\n",
    "                gdf_output['DGA_Caudal_Ls'].max(),\n",
    "                (gdf_output['DGA_Caudal_Ls'] > 0).sum(),\n",
    "                '',\n",
    "                '',\n",
    "                ws_totals['Red Publica'],\n",
    "                ws_totals['Pozo o Noria'],\n",
    "                ws_totals['Camion Aljibe'],\n",
    "                ws_totals['Rio/Vertiente/Estero'],\n",
    "                ws_grand_total,\n",
    "                '',\n",
    "                '',\n",
    "                (ws_totals['Red Publica'] / ws_grand_total * 100) if ws_grand_total > 0 else 0,\n",
    "                (ws_totals['Pozo o Noria'] / ws_grand_total * 100) if ws_grand_total > 0 else 0,\n",
    "                (ws_totals['Camion Aljibe'] / ws_grand_total * 100) if ws_grand_total > 0 else 0,\n",
    "                (ws_totals['Rio/Vertiente/Estero'] / ws_grand_total * 100) if ws_grand_total > 0 else 0,\n",
    "                '',\n",
    "                '',\n",
    "                (gdf_output['Comparison'] == 'Census_Higher_Than_DGA').sum(),\n",
    "                (gdf_output['Comparison'] == 'DGA_Higher_Than_Census').sum(),\n",
    "                (gdf_output['Comparison'] == 'DGA_Equals_Census').sum(),\n",
    "                (gdf_output['Comparison'] == 'No_Wells_No_Rights').sum(),\n",
    "                '',\n",
    "                '',\n",
    "                gdf_output['Is_Rural'].sum(),\n",
    "                len(gdf_output) - gdf_output['Is_Rural'].sum(),\n",
    "                gdf_output['Personas_24'].sum(),\n",
    "                gdf_output['Viviendas_24'].sum(),\n",
    "                gdf_output['Viv_Total_24'].sum()\n",
    "            ]\n",
    "        })\n",
    "        national_summary.to_excel(writer, sheet_name='National_Summary', index=False)\n",
    "        \n",
    "        df_block_sample = df_block.head(50000)\n",
    "        df_block_sample.to_excel(writer, sheet_name='Block_Level_Sample', index=False)\n",
    "        \n",
    "        for level_name, stats in all_stats.items():\n",
    "            sheet_name = f'{level_name}_Level'\n",
    "            stats.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        primary_ws_summary = gdf_output.groupby('Primary_WS').agg({\n",
    "            'Census_Wells': 'sum',\n",
    "            'DGA_WaterRights': 'sum',\n",
    "            'DGA_Caudal_Ls': 'sum',\n",
    "            'DGA_Caudal_m3y': 'sum',\n",
    "            'WS_RedPublica': 'sum',\n",
    "            'WS_Pozo': 'sum',\n",
    "            'WS_Camion': 'sum',\n",
    "            'WS_Rio': 'sum',\n",
    "            'Personas_24': 'sum',\n",
    "            'Viviendas_24': 'sum'\n",
    "        }).reset_index()\n",
    "        primary_ws_summary['N_Blocks'] = gdf_output.groupby('Primary_WS').size().values\n",
    "        primary_ws_summary.to_excel(writer, sheet_name='By_Primary_WaterSource', index=False)\n",
    "        \n",
    "        top_caudal_blocks = df_block.nlargest(100, 'DGA_Caudal_Ls')\n",
    "        top_caudal_blocks.to_excel(writer, sheet_name='Top_100_Blocks_by_Caudal', index=False)\n",
    "        \n",
    "        interpretation = pd.DataFrame({\n",
    "            'Column': [\n",
    "                '--- COMPARISON COLUMNS ---',\n",
    "                'Census_Wells',\n",
    "                'DGA_WaterRights',\n",
    "                'Delta_DGA_Census',\n",
    "                'Delta_Census_DGA',\n",
    "                'Comparison',\n",
    "                '',\n",
    "                '--- DGA CAUDAL (FLOW RATE) COLUMNS ---',\n",
    "                'DGA_Caudal_Ls',\n",
    "                'DGA_Caudal_m3y',\n",
    "                'DGA_Caudal_Mean',\n",
    "                'DGA_Caudal_Median',\n",
    "                'DGA_Caudal_Max',\n",
    "                'DGA_Caudal_Min',\n",
    "                'DGA_Caudal_Mean_m3y',\n",
    "                'DGA_Caudal_Median_m3y',\n",
    "                'DGA_Caudal_Max_m3y',\n",
    "                'DGA_Caudal_Min_m3y',\n",
    "                'Caudal_per_CensusWell',\n",
    "                '',\n",
    "                '--- WATER SOURCE COLUMNS ---',\n",
    "                'WS_RedPublica',\n",
    "                'WS_Pozo',\n",
    "                'WS_Camion',\n",
    "                'WS_Rio',\n",
    "                'WS_Total',\n",
    "                'Primary_WS',\n",
    "                'Primary_WS_Pct',\n",
    "                '',\n",
    "                '--- CONVERSION ---',\n",
    "                'L/s to m³/year'\n",
    "            ],\n",
    "            'Description': [\n",
    "                '',\n",
    "                'Number of households reporting well (Pozo) as water source in Census 2024',\n",
    "                'Number of DGA water rights (points) within census block',\n",
    "                'DGA Water Rights MINUS Census Wells',\n",
    "                'Census Wells MINUS DGA Water Rights',\n",
    "                'Classification of comparison result',\n",
    "                '',\n",
    "                '',\n",
    "                'Sum of DGA water rights flow rates in Liters per Second',\n",
    "                'Sum of DGA water rights flow rates in Cubic Meters per Year',\n",
    "                'Average flow rate of DGA rights in the block (L/s)',\n",
    "                'Median flow rate of DGA rights in the block (L/s)',\n",
    "                'Maximum flow rate of DGA rights in the block (L/s)',\n",
    "                'Minimum flow rate of DGA rights in the block (L/s)',\n",
    "                'Average flow rate of DGA rights in the block (m3/year)',\n",
    "                'Median flow rate of DGA rights in the block (m3/year)',\n",
    "                'Maximum flow rate of DGA rights in the block (m3/year)',\n",
    "                'Minimum flow rate of DGA rights in the block (m3/year)',\n",
    "                'Total Caudal divided by number of Census Wells (L/s per well)',\n",
    "                '',\n",
    "                '',\n",
    "                'Households with public water network connection',\n",
    "                'Households with well (pozo) as water source',\n",
    "                'Households supplied by water truck (camion aljibe)',\n",
    "                'Households using river/spring/stream water',\n",
    "                'Total households with water source data',\n",
    "                'Dominant water source type in census block',\n",
    "                'Percentage of households using primary water source',\n",
    "                '',\n",
    "                '',\n",
    "                f'1 L/s = {LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR:,.2f} m³/year'\n",
    "            ]\n",
    "        })\n",
    "        interpretation.to_excel(writer, sheet_name='Column_Definitions', index=False)\n",
    "    \n",
    "    print(f\"   Saved: {combined_path}\")\n",
    "    \n",
    "    for level_name, stats in all_stats.items():\n",
    "        level_path = os.path.join(OUTPUT_FOLDER, 'Excel', f'Census2024_vs_DGA_{level_name}_Level.xlsx')\n",
    "        \n",
    "        with pd.ExcelWriter(level_path, engine='openpyxl') as writer:\n",
    "            stats.to_excel(writer, sheet_name='All_Data', index=False)\n",
    "            \n",
    "            census_higher = stats[stats['Agg_Comparison'] == 'Census_Higher'].copy()\n",
    "            census_higher = census_higher.sort_values('Delta_Census_DGA', ascending=False)\n",
    "            census_higher.to_excel(writer, sheet_name='Census_Higher_Than_DGA', index=False)\n",
    "            \n",
    "            dga_higher = stats[stats['Agg_Comparison'] == 'DGA_Higher'].copy()\n",
    "            dga_higher = dga_higher.sort_values('Delta_DGA_Census', ascending=False)\n",
    "            dga_higher.to_excel(writer, sheet_name='DGA_Higher_Than_Census', index=False)\n",
    "            \n",
    "            top_caudal = stats.nlargest(20, 'DGA_Caudal_Ls')\n",
    "            top_caudal.to_excel(writer, sheet_name='Top_20_by_Caudal', index=False)\n",
    "            \n",
    "            by_dominant_ws = stats.groupby('Dominant_WS').agg({\n",
    "                'N_Blocks': 'sum',\n",
    "                'Census_Wells': 'sum',\n",
    "                'DGA_WaterRights': 'sum',\n",
    "                'DGA_Caudal_Ls': 'sum',\n",
    "                'DGA_Caudal_m3y': 'sum',\n",
    "                'Delta_Census_DGA': 'sum',\n",
    "                'WS_RedPublica': 'sum',\n",
    "                'WS_Pozo': 'sum',\n",
    "                'WS_Camion': 'sum',\n",
    "                'WS_Rio': 'sum',\n",
    "                'Personas_24': 'sum'\n",
    "            }).reset_index()\n",
    "            by_dominant_ws.to_excel(writer, sheet_name='By_Dominant_WaterSource', index=False)\n",
    "            \n",
    "            name_col = [c for c in stats.columns if c.endswith('_Name')][0]\n",
    "            level_summary = pd.DataFrame({\n",
    "                'Metric': [\n",
    "                    f'Total {level_name}s',\n",
    "                    'Census Wells Total',\n",
    "                    'DGA Rights Total',\n",
    "                    'Net Delta (Census - DGA)',\n",
    "                    f'{level_name}s with Census > DGA',\n",
    "                    f'{level_name}s with DGA > Census',\n",
    "                    f'{level_name}s with Equal',\n",
    "                    '',\n",
    "                    '--- DGA CAUDAL ---',\n",
    "                    'Total Caudal (L/s)',\n",
    "                    'Total Caudal (m³/year)',\n",
    "                    'Average Caudal per DGA Right (L/s)',\n",
    "                    f'{level_name} with highest Caudal',\n",
    "                    'Highest Caudal value (L/s)',\n",
    "                    '',\n",
    "                    '--- WATER SOURCES ---',\n",
    "                    'Red Publica Total',\n",
    "                    'Pozo Total',\n",
    "                    'Camion Total',\n",
    "                    'Rio Total',\n",
    "                    '',\n",
    "                    '--- DOMINANT WATER SOURCE ---',\n",
    "                    f'{level_name}s with RedPublica dominant',\n",
    "                    f'{level_name}s with Pozo dominant',\n",
    "                    f'{level_name}s with Camion dominant',\n",
    "                    f'{level_name}s with Rio dominant'\n",
    "                ],\n",
    "                'Value': [\n",
    "                    len(stats),\n",
    "                    stats['Census_Wells'].sum(),\n",
    "                    stats['DGA_WaterRights'].sum(),\n",
    "                    stats['Delta_Census_DGA'].sum(),\n",
    "                    (stats['Agg_Comparison'] == 'Census_Higher').sum(),\n",
    "                    (stats['Agg_Comparison'] == 'DGA_Higher').sum(),\n",
    "                    (stats['Agg_Comparison'] == 'Equal').sum(),\n",
    "                    '',\n",
    "                    '',\n",
    "                    stats['DGA_Caudal_Ls'].sum(),\n",
    "                    stats['DGA_Caudal_m3y'].sum(),\n",
    "                    (stats['DGA_Caudal_Ls'].sum() / stats['DGA_WaterRights'].sum()) if stats['DGA_WaterRights'].sum() > 0 else 0,\n",
    "                    stats.loc[stats['DGA_Caudal_Ls'].idxmax(), name_col] if len(stats) > 0 else 'N/A',\n",
    "                    stats['DGA_Caudal_Ls'].max(),\n",
    "                    '',\n",
    "                    '',\n",
    "                    stats['WS_RedPublica'].sum(),\n",
    "                    stats['WS_Pozo'].sum(),\n",
    "                    stats['WS_Camion'].sum(),\n",
    "                    stats['WS_Rio'].sum(),\n",
    "                    '',\n",
    "                    '',\n",
    "                    (stats['Dominant_WS'] == 'RedPublica').sum(),\n",
    "                    (stats['Dominant_WS'] == 'Pozo').sum(),\n",
    "                    (stats['Dominant_WS'] == 'Camion').sum(),\n",
    "                    (stats['Dominant_WS'] == 'Rio').sum()\n",
    "                ]\n",
    "            })\n",
    "            level_summary.to_excel(writer, sheet_name='Summary', index=False)\n",
    "        \n",
    "        print(f\"   Saved: {level_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 12: Generating text report...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    report_lines = []\n",
    "    report_lines.append(\"=\"*100)\n",
    "    report_lines.append(\"DGA WATER RIGHTS vs CENSUS 2024 WELLS COMPARISON REPORT\")\n",
    "    report_lines.append(\"Including All Water Sources and DGA Flow Rates (Caudal)\")\n",
    "    report_lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    report_lines.append(\"\\nDELTA CALCULATION:\")\n",
    "    report_lines.append(\"  Delta = DGA Water Rights - Census Wells (Pozo)\")\n",
    "    report_lines.append(\"  Positive Delta: More DGA rights than census wells\")\n",
    "    report_lines.append(\"  Negative Delta: More census wells than DGA rights (potential unregistered)\")\n",
    "    \n",
    "    report_lines.append(\"\\nCAUDAL CONVERSION:\")\n",
    "    report_lines.append(f\"  1 L/s = {LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR:,.2f} m³/year\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*80)\n",
    "    report_lines.append(\"NATIONAL SUMMARY\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(f\"Total Census Blocks: {len(gdf_output):,}\")\n",
    "    report_lines.append(f\"Total Population: {gdf_output['Personas_24'].sum():,}\")\n",
    "    report_lines.append(f\"Total Households: {gdf_output['Viviendas_24'].sum():,}\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- DGA vs CENSUS COMPARISON ---\")\n",
    "    report_lines.append(f\"Total Census Wells (Pozo): {gdf_output['Census_Wells'].sum():,}\")\n",
    "    report_lines.append(f\"Total DGA Water Rights: {gdf_output['DGA_WaterRights'].sum():,}\")\n",
    "    report_lines.append(f\"Delta (DGA - Census): {gdf_output['Delta_DGA_Census'].sum():,}\")\n",
    "    report_lines.append(f\"Delta (Census - DGA): {gdf_output['Delta_Census_DGA'].sum():,}\")\n",
    "    \n",
    "    coverage_rate = (gdf_output['DGA_WaterRights'].sum() / gdf_output['Census_Wells'].sum() * 100) if gdf_output['Census_Wells'].sum() > 0 else 0\n",
    "    report_lines.append(f\"DGA Coverage Rate: {coverage_rate:.2f}%\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- DGA FLOW RATES (CAUDAL) ---\")\n",
    "    total_caudal_ls = gdf_output['DGA_Caudal_Ls'].sum()\n",
    "    total_caudal_m3y = gdf_output['DGA_Caudal_m3y'].sum()\n",
    "    report_lines.append(f\"Total Caudal: {total_caudal_ls:,.2f} L/s\")\n",
    "    report_lines.append(f\"Total Caudal: {total_caudal_m3y:,.2f} m³/year\")\n",
    "    report_lines.append(f\"Average Caudal per DGA Right: {(total_caudal_ls / gdf_output['DGA_WaterRights'].sum()) if gdf_output['DGA_WaterRights'].sum() > 0 else 0:.2f} L/s\")\n",
    "    report_lines.append(f\"Average Caudal per Census Well: {(total_caudal_ls / gdf_output['Census_Wells'].sum()) if gdf_output['Census_Wells'].sum() > 0 else 0:.2f} L/s\")\n",
    "    report_lines.append(f\"Max Caudal in single block: {gdf_output['DGA_Caudal_Ls'].max():,.2f} L/s\")\n",
    "    report_lines.append(f\"Blocks with Caudal > 0: {(gdf_output['DGA_Caudal_Ls'] > 0).sum():,}\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- WATER SOURCES SUMMARY ---\")\n",
    "    report_lines.append(f\"{'Source':<30} {'Households':>15} {'Percentage':>12}\")\n",
    "    report_lines.append(\"-\"*60)\n",
    "    ws_grand_total = gdf_output['WS_Total'].sum()\n",
    "    for src_key, src_info in WATER_SOURCES.items():\n",
    "        col_ws = f\"WS_{src_info['name_short']}\"\n",
    "        total = gdf_output[col_ws].sum()\n",
    "        pct = (total / ws_grand_total * 100) if ws_grand_total > 0 else 0\n",
    "        report_lines.append(f\"{src_info['name']:<30} {total:>15,} {pct:>11.2f}%\")\n",
    "    report_lines.append(f\"{'TOTAL':<30} {ws_grand_total:>15,} {'100.00':>11}%\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- PRIMARY WATER SOURCE BY BLOCKS ---\")\n",
    "    primary_counts = gdf_output['Primary_WS'].value_counts()\n",
    "    for src, count in primary_counts.items():\n",
    "        pct = count / len(gdf_output) * 100\n",
    "        report_lines.append(f\"  {src}: {count:,} blocks ({pct:.1f}%)\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- COMPARISON CLASSIFICATION ---\")\n",
    "    for comp_type in ['Census_Higher_Than_DGA', 'DGA_Higher_Than_Census', 'DGA_Equals_Census', 'No_Wells_No_Rights']:\n",
    "        count = (gdf_output['Comparison'] == comp_type).sum()\n",
    "        pct = count / len(gdf_output) * 100\n",
    "        report_lines.append(f\"  {comp_type}: {count:,} blocks ({pct:.1f}%)\")\n",
    "    \n",
    "    for level_name, stats in all_stats.items():\n",
    "        name_col = [c for c in stats.columns if c.endswith('_Name')][0]\n",
    "        \n",
    "        report_lines.append(f\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(f\"{level_name.upper()} LEVEL ANALYSIS\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(f\"Total units: {len(stats)}\")\n",
    "        report_lines.append(f\"Total Census Wells: {stats['Census_Wells'].sum():,}\")\n",
    "        report_lines.append(f\"Total DGA Rights: {stats['DGA_WaterRights'].sum():,}\")\n",
    "        report_lines.append(f\"Net Delta (Census - DGA): {stats['Delta_Census_DGA'].sum():,}\")\n",
    "        \n",
    "        report_lines.append(f\"\\n--- DGA CAUDAL ---\")\n",
    "        report_lines.append(f\"  Total Caudal: {stats['DGA_Caudal_Ls'].sum():,.2f} L/s = {stats['DGA_Caudal_m3y'].sum():,.2f} m³/year\")\n",
    "        \n",
    "        report_lines.append(f\"\\n--- WATER SOURCES ---\")\n",
    "        report_lines.append(f\"  Red Publica: {stats['WS_RedPublica'].sum():,}\")\n",
    "        report_lines.append(f\"  Pozo: {stats['WS_Pozo'].sum():,}\")\n",
    "        report_lines.append(f\"  Camion: {stats['WS_Camion'].sum():,}\")\n",
    "        report_lines.append(f\"  Rio: {stats['WS_Rio'].sum():,}\")\n",
    "        \n",
    "        report_lines.append(f\"\\n--- TOP 10: HIGHEST CAUDAL (FLOW RATE) ---\")\n",
    "        top_caudal = stats.nlargest(10, 'DGA_Caudal_Ls')\n",
    "        report_lines.append(f\"{'Rank':<5} {level_name:<35} {'Caudal L/s':>15} {'Caudal m³/y':>18} {'DGA Rights':>12}\")\n",
    "        report_lines.append(\"-\"*90)\n",
    "        for i, (_, row) in enumerate(top_caudal.iterrows(), 1):\n",
    "            name = str(row[name_col])[:33]\n",
    "            report_lines.append(f\"{i:<5} {name:<35} {row['DGA_Caudal_Ls']:>15,.2f} {row['DGA_Caudal_m3y']:>18,.2f} {row['DGA_WaterRights']:>12,.0f}\")\n",
    "        \n",
    "        report_lines.append(f\"\\n--- TOP 10: HIGHEST CENSUS > DGA (Potential Unregistered Wells) ---\")\n",
    "        top_census = stats[stats['Agg_Comparison'] == 'Census_Higher'].nlargest(10, 'Delta_Census_DGA')\n",
    "        report_lines.append(f\"{'Rank':<5} {level_name:<35} {'Census':>10} {'DGA':>10} {'Delta':>10} {'Caudal L/s':>12}\")\n",
    "        report_lines.append(\"-\"*90)\n",
    "        for i, (_, row) in enumerate(top_census.iterrows(), 1):\n",
    "            name = str(row[name_col])[:33]\n",
    "            report_lines.append(f\"{i:<5} {name:<35} {row['Census_Wells']:>10,.0f} {row['DGA_WaterRights']:>10,.0f} {row['Delta_Census_DGA']:>+10,.0f} {row['DGA_Caudal_Ls']:>12,.2f}\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(\"OUTPUT FILES GENERATED:\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    report_lines.append(f\"Shapefile: {os.path.join(OUTPUT_FOLDER, 'Shapefiles', 'Census2024_vs_DGA_Comparison.shp')}\")\n",
    "    report_lines.append(f\"Excel (All Levels): {combined_path}\")\n",
    "    report_lines.append(f\"Excel (Block Level): {block_excel_path}\")\n",
    "    for level_name in all_stats.keys():\n",
    "        report_lines.append(f\"Excel ({level_name}): {os.path.join(OUTPUT_FOLDER, 'Excel', f'Census2024_vs_DGA_{level_name}_Level.xlsx')}\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(\"SHAPEFILE COLUMNS:\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    report_lines.append(\"Comparison: Cens_Well, DGA_Rights, Delta_DGA, Delta_Cens, Comparison\")\n",
    "    report_lines.append(\"Caudal: DGA_Q_Ls (L/s), DGA_Q_m3y (m³/year), DGA_Q_Mean, DGA_Q_Max, DGA_Q_Min, Q_perWell\")\n",
    "    report_lines.append(\"Water Sources: WS_RedPub, WS_Pozo, WS_Camion, WS_Rio, WS_Total\")\n",
    "    report_lines.append(\"Percentages: Pct_RedPub, Pct_Pozo, Pct_Camion, Pct_Rio\")\n",
    "    report_lines.append(\"Primary: Prim_WS, Prim_WS_Pc\")\n",
    "    report_lines.append(\"Demographics: Personas, Viviendas, Viv_Total, Area_Type, Is_Rural\")\n",
    "    report_lines.append(\"Spatial: Muni_Name, Muni_Code, Reg_Name, Reg_Code, Cuen_Name, Cuen_Code, SHAC_Name, SHAC_Code\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(\"END OF REPORT\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    report_path = os.path.join(OUTPUT_FOLDER, 'Reports', f'DGA_vs_Census_Report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(report_lines))\n",
    "    print(f\"   Saved: {report_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"\\n\".join(report_lines[:100]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nOutput folder: {OUTPUT_FOLDER}\")\n",
    "    print(f\"\\nFiles generated:\")\n",
    "    print(f\"  - Shapefile: Shapefiles/Census2024_vs_DGA_Comparison.shp\")\n",
    "    print(f\"  - Excel (All Levels): Excel/Census2024_vs_DGA_All_Levels.xlsx\")\n",
    "    print(f\"  - Excel (Block Level): Excel/Census2024_vs_DGA_Block_Level.xlsx\")\n",
    "    for level_name in all_stats.keys():\n",
    "        print(f\"  - Excel ({level_name}): Excel/Census2024_vs_DGA_{level_name}_Level.xlsx\")\n",
    "    print(f\"  - Report: Reports/DGA_vs_Census_Report_*.txt\")\n",
    "    \n",
    "    print(f\"\\nFinished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9e1ac-b704-4c2e-bee0-581ee8730c2b",
   "metadata": {},
   "source": [
    "# Water Consumption Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be3be1-e154-4158-80e3-8ef6140e24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "INPUT_SHAPEFILE = r\"\\assessment_of_wells_chile\\data\\DGA_vs_Census_Comparison\\Shapefiles\\Census2024_vs_DGA_Comparison.shp\"\n",
    "\n",
    "OUTPUT_FOLDER = r\"\\assessment_of_wells_chile\\data\\Groundwater_Extraction_Estimates\"\n",
    "\n",
    "C_PC_DOMESTIC = 150\n",
    "C_PC_ENHANCED = 250\n",
    "H_AVG_DEFAULT = 3.1\n",
    "\n",
    "P_PRODUCTIVE = 0.25\n",
    "Q_PRODUCTIVE_LS = 1.0\n",
    "\n",
    "SECONDS_PER_DAY = 86400\n",
    "SECONDS_PER_YEAR = 86400 * 365\n",
    "LITERS_TO_M3 = 0.001\n",
    "LITERS_PER_SECOND_TO_CUBIC_METERS_PER_YEAR = 31557.6\n",
    "\n",
    "SENSITIVITY_PARAMS = {\n",
    "    'C_pc': {'min': 105, 'base': 150, 'max': 195},\n",
    "    'p_productive': {'min': 0.15, 'base': 0.25, 'max': 0.35},\n",
    "    'q_productive': {'min': 0.5, 'base': 1.0, 'max': 1.5}\n",
    "}\n",
    "\n",
    "SHP_COL_MAP = {\n",
    "    'Cens_Well': 'Census_Wells',\n",
    "    'DGA_Rights': 'DGA_WaterRights',\n",
    "    'Delta_DGA': 'Delta_DGA_Census',\n",
    "    'Delta_Cens': 'Delta_Census_DGA',\n",
    "    'Comparison': 'Comparison',\n",
    "    'Comp_Det': 'Comparison_Detail',\n",
    "    'DGA_Q_Ls': 'DGA_Caudal_Ls',\n",
    "    'DGA_Q_Mean': 'DGA_Caudal_Mean',\n",
    "    'DGA_Q_Med': 'DGA_Caudal_Median',\n",
    "    'DGA_Q_Max': 'DGA_Caudal_Max',\n",
    "    'DGA_Q_Min': 'DGA_Caudal_Min',\n",
    "    'DGA_Q_m3y': 'DGA_Caudal_m3y',\n",
    "    'Q_Mean_m3y': 'DGA_Caudal_Mean_m3y',\n",
    "    'Q_Med_m3y': 'DGA_Caudal_Median_m3y',\n",
    "    'Q_Max_m3y': 'DGA_Caudal_Max_m3y',\n",
    "    'Q_Min_m3y': 'DGA_Caudal_Min_m3y',\n",
    "    'Q_perWell': 'Caudal_per_CensusWell',\n",
    "    'WS_RedPub': 'WS_RedPublica',\n",
    "    'WS_Pozo': 'WS_Pozo',\n",
    "    'WS_Camion': 'WS_Camion',\n",
    "    'WS_Rio': 'WS_Rio',\n",
    "    'WS_Total': 'WS_Total',\n",
    "    'Pct_RedPub': 'Pct_RedPublica',\n",
    "    'Pct_Pozo': 'Pct_Pozo',\n",
    "    'Pct_Camion': 'Pct_Camion',\n",
    "    'Pct_Rio': 'Pct_Rio',\n",
    "    'Prim_WS': 'Primary_WS',\n",
    "    'Prim_WS_Pc': 'Primary_WS_Pct',\n",
    "    'Personas': 'Personas_24',\n",
    "    'Viviendas': 'Viviendas_24',\n",
    "    'Viv_Total': 'Viv_Total_24',\n",
    "    'Area_Type': 'Area_Type',\n",
    "    'Is_Rural': 'Is_Rural',\n",
    "    'Muni_Name': 'Muni_Name',\n",
    "    'Muni_Code': 'Muni_Code',\n",
    "    'Reg_Name': 'Region_Name',\n",
    "    'Reg_Code': 'Region_Code',\n",
    "    'Cuen_Name': 'Cuenca_Name',\n",
    "    'Cuen_Code': 'Cuenca_Code',\n",
    "    'SHAC_Name': 'SHAC_Name',\n",
    "    'SHAC_Code': 'SHAC_Code',\n",
    "    'Cent_Lon': 'Centroid_Lon',\n",
    "    'Cent_Lat': 'Centroid_Lat'\n",
    "}\n",
    "\n",
    "REVERSE_COL_MAP = {v: k for k, v in SHP_COL_MAP.items()}\n",
    "\n",
    "def create_output_folder(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    subfolders = ['Shapefiles', 'CSV', 'Excel', 'Reports']\n",
    "    for f in subfolders:\n",
    "        Path(os.path.join(path, f)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rename_shapefile_columns(gdf):\n",
    "    rename_dict = {}\n",
    "    for shp_col, full_col in SHP_COL_MAP.items():\n",
    "        if shp_col in gdf.columns:\n",
    "            rename_dict[shp_col] = full_col\n",
    "    return gdf.rename(columns=rename_dict)\n",
    "\n",
    "def prepare_shapefile_columns(gdf):\n",
    "    rename_dict = {}\n",
    "    for col in gdf.columns:\n",
    "        if col == 'geometry':\n",
    "            continue\n",
    "        if col in REVERSE_COL_MAP:\n",
    "            rename_dict[col] = REVERSE_COL_MAP[col]\n",
    "        elif len(col) > 10:\n",
    "            rename_dict[col] = col[:10]\n",
    "    return gdf.rename(columns=rename_dict)\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"GROUNDWATER EXTRACTION ESTIMATION FROM CENSUS vs DGA COMPARISON\")\n",
    "    print(\"Using Pre-Processed Shapefile from Code 1\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    create_output_folder(OUTPUT_FOLDER)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 1: Loading shapefile from Code 1...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    if not os.path.exists(INPUT_SHAPEFILE):\n",
    "        print(f\"   ERROR: Input shapefile not found: {INPUT_SHAPEFILE}\")\n",
    "        print(\"   Please run Code 1 first to generate the shapefile.\")\n",
    "        return\n",
    "    \n",
    "    gdf = gpd.read_file(INPUT_SHAPEFILE)\n",
    "    print(f\"   ✅ Loaded {len(gdf):,} census blocks from shapefile\")\n",
    "    print(f\"   CRS: {gdf.crs}\")\n",
    "    print(f\"   Original columns: {list(gdf.columns)}\")\n",
    "    \n",
    "    gdf = rename_shapefile_columns(gdf)\n",
    "    print(f\"   Renamed columns: {list(gdf.columns)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 2: Validating and preparing data...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    required_cols = ['Census_Wells', 'DGA_WaterRights', 'Personas_24', 'Viviendas_24', 'Is_Rural']\n",
    "    missing_cols = [c for c in required_cols if c not in gdf.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"   ⚠️ Missing columns: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            for existing_col in gdf.columns:\n",
    "                if col.lower() in existing_col.lower():\n",
    "                    print(f\"      Found alternative: {existing_col} for {col}\")\n",
    "    \n",
    "    numeric_cols = ['Census_Wells', 'DGA_WaterRights', 'Personas_24', 'Viviendas_24', \n",
    "                    'Is_Rural', 'WS_RedPublica', 'WS_Pozo', 'WS_Camion', 'WS_Rio',\n",
    "                    'DGA_Caudal_Ls', 'DGA_Caudal_m3y']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in gdf.columns:\n",
    "            gdf[col] = pd.to_numeric(gdf[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    print(f\"\\n   === DATA SUMMARY ===\")\n",
    "    print(f\"   Total census blocks: {len(gdf):,}\")\n",
    "    print(f\"   Total Census Wells: {gdf['Census_Wells'].sum():,.0f}\")\n",
    "    print(f\"   Total DGA Rights: {gdf['DGA_WaterRights'].sum():,.0f}\")\n",
    "    print(f\"   Total Population: {gdf['Personas_24'].sum():,.0f}\")\n",
    "    print(f\"   Total Households: {gdf['Viviendas_24'].sum():,.0f}\")\n",
    "    print(f\"   Rural blocks: {gdf['Is_Rural'].sum():,.0f}\")\n",
    "    print(f\"   Urban blocks: {(gdf['Is_Rural'] == 0).sum():,.0f}\")\n",
    "    \n",
    "    if 'DGA_Caudal_Ls' in gdf.columns:\n",
    "        print(f\"   Total DGA Caudal: {gdf['DGA_Caudal_Ls'].sum():,.2f} L/s\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 3: Calculating household size (H_avg)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf['H_Block'] = np.where(\n",
    "        gdf['Viviendas_24'] > 0,\n",
    "        gdf['Personas_24'] / gdf['Viviendas_24'],\n",
    "        H_AVG_DEFAULT\n",
    "    )\n",
    "    \n",
    "    gdf['Used_Default_H'] = np.where(gdf['Viviendas_24'] > 0, 0, 1)\n",
    "    \n",
    "    total_personas = gdf['Personas_24'].sum()\n",
    "    total_viviendas = gdf['Viviendas_24'].sum()\n",
    "    H_AVG_NATIONAL = total_personas / total_viviendas if total_viviendas > 0 else H_AVG_DEFAULT\n",
    "    \n",
    "    blocks_with_real_h = (gdf['Used_Default_H'] == 0).sum()\n",
    "    blocks_with_default_h = (gdf['Used_Default_H'] == 1).sum()\n",
    "    pct_real_h = (blocks_with_real_h / len(gdf)) * 100\n",
    "    \n",
    "    print(f\"   National average H_avg: {H_AVG_NATIONAL:.2f} persons/household\")\n",
    "    print(f\"   Blocks with calculated H_avg: {blocks_with_real_h:,} ({pct_real_h:.1f}%)\")\n",
    "    print(f\"   Blocks using default ({H_AVG_DEFAULT}): {blocks_with_default_h:,}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 4: Calculating discrepancy (unregistered wells)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf['Discrepancy'] = (gdf['Census_Wells'] - gdf['DGA_WaterRights']).clip(lower=0)\n",
    "    \n",
    "    gdf['Ratio_Census_DGA'] = np.where(\n",
    "        gdf['DGA_WaterRights'] > 0,\n",
    "        gdf['Census_Wells'] / gdf['DGA_WaterRights'],\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    total_discrepancy = gdf['Discrepancy'].sum()\n",
    "    total_census = gdf['Census_Wells'].sum()\n",
    "    total_dga = gdf['DGA_WaterRights'].sum()\n",
    "    \n",
    "    print(f\"   Total Census Wells: {total_census:,.0f}\")\n",
    "    print(f\"   Total DGA Rights: {total_dga:,.0f}\")\n",
    "    print(f\"   Total Discrepancy (potential unregistered): {total_discrepancy:,.0f}\")\n",
    "    print(f\"   Ratio Census/DGA: {total_census/total_dga:.2f}x\" if total_dga > 0 else \"   Ratio: N/A\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 5: Calculating exclusive well dependence (p_exclusive)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    if 'WS_RedPublica' in gdf.columns:\n",
    "        gdf['Pozos_Exclusivos'] = (gdf['Census_Wells'] - gdf['WS_RedPublica']).clip(lower=0)\n",
    "    else:\n",
    "        gdf['Pozos_Exclusivos'] = gdf['Census_Wells']\n",
    "    \n",
    "    gdf['p_exclusive'] = np.where(\n",
    "        gdf['Census_Wells'] > 0,\n",
    "        gdf['Pozos_Exclusivos'] / gdf['Census_Wells'],\n",
    "        1.0\n",
    "    )\n",
    "    gdf['p_exclusive'] = gdf['p_exclusive'].clip(0, 1)\n",
    "    \n",
    "    p_exclusive_national = gdf['Pozos_Exclusivos'].sum() / gdf['Census_Wells'].sum() if gdf['Census_Wells'].sum() > 0 else 1.0\n",
    "    \n",
    "    print(f\"   National p_exclusive: {p_exclusive_national:.2%}\")\n",
    "    print(f\"   Meaning: {p_exclusive_national*100:.1f}% of well users have NO public network access\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 6: Calculating rural proportion (p_rural)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf['p_rural'] = gdf['Is_Rural'].astype(float)\n",
    "    \n",
    "    rural_wells = (gdf['Census_Wells'] * gdf['Is_Rural']).sum()\n",
    "    total_wells = gdf['Census_Wells'].sum()\n",
    "    p_rural_national = rural_wells / total_wells if total_wells > 0 else 0\n",
    "    \n",
    "    print(f\"   Total rural wells: {rural_wells:,.0f}\")\n",
    "    print(f\"   Total wells: {total_wells:,.0f}\")\n",
    "    print(f\"   National p_rural: {p_rural_national:.2%}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 7: Calculating Scenario 1 (Uniform Domestic Demand)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf['q_dom_Ls'] = (C_PC_DOMESTIC * gdf['H_Block']) / SECONDS_PER_DAY\n",
    "    \n",
    "    gdf['Q_S1_Ls'] = gdf['Discrepancy'] * gdf['q_dom_Ls']\n",
    "    gdf['Q_S1_m3_day'] = gdf['Q_S1_Ls'] * SECONDS_PER_DAY * LITERS_TO_M3\n",
    "    gdf['Q_S1_m3_year'] = gdf['Q_S1_Ls'] * SECONDS_PER_YEAR * LITERS_TO_M3\n",
    "    \n",
    "    total_Q_S1_Ls = gdf['Q_S1_Ls'].sum()\n",
    "    total_Q_S1_m3_year = gdf['Q_S1_m3_year'].sum()\n",
    "    \n",
    "    print(f\"   Parameters: C_pc = {C_PC_DOMESTIC} L/person/day\")\n",
    "    print(f\"   Total unregistered extraction (S1):\")\n",
    "    print(f\"      - {total_Q_S1_Ls:,.2f} L/s\")\n",
    "    print(f\"      - {total_Q_S1_m3_year:,.0f} m³/year\")\n",
    "    print(f\"      - {total_Q_S1_m3_year/1e6:,.2f} million m³/year\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 8: Calculating Scenario 2 (Stratified Demand)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf['q_enhanced_Ls'] = (C_PC_ENHANCED * gdf['H_Block']) / SECONDS_PER_DAY\n",
    "    \n",
    "    gdf['q_S2_Ls'] = (gdf['p_exclusive'] * gdf['q_enhanced_Ls'] + \n",
    "                      (1 - gdf['p_exclusive']) * gdf['q_dom_Ls'])\n",
    "    \n",
    "    gdf['Q_S2_Ls'] = gdf['Discrepancy'] * gdf['q_S2_Ls']\n",
    "    gdf['Q_S2_m3_day'] = gdf['Q_S2_Ls'] * SECONDS_PER_DAY * LITERS_TO_M3\n",
    "    gdf['Q_S2_m3_year'] = gdf['Q_S2_Ls'] * SECONDS_PER_YEAR * LITERS_TO_M3\n",
    "    \n",
    "    total_Q_S2_Ls = gdf['Q_S2_Ls'].sum()\n",
    "    total_Q_S2_m3_year = gdf['Q_S2_m3_year'].sum()\n",
    "    \n",
    "    print(f\"   Parameters: C_enhanced = {C_PC_ENHANCED} L/person/day\")\n",
    "    print(f\"   Total unregistered extraction (S2):\")\n",
    "    print(f\"      - {total_Q_S2_Ls:,.2f} L/s\")\n",
    "    print(f\"      - {total_Q_S2_m3_year:,.0f} m³/year\")\n",
    "    print(f\"      - {total_Q_S2_m3_year/1e6:,.2f} million m³/year\")\n",
    "    print(f\"   Increase over S1: {((total_Q_S2_m3_year/total_Q_S1_m3_year)-1)*100:+.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 9: Calculating Scenario 3 (Mixed-Use with Productive)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    gdf['Rural_Productive_Ls'] = P_PRODUCTIVE * Q_PRODUCTIVE_LS\n",
    "    gdf['Rural_Domestic_Ls'] = (1 - P_PRODUCTIVE) * gdf['q_S2_Ls']\n",
    "    gdf['Rural_Rate_Ls'] = gdf['Rural_Productive_Ls'] + gdf['Rural_Domestic_Ls']\n",
    "    \n",
    "    gdf['Urban_Rate_Ls'] = gdf['q_S2_Ls']\n",
    "    \n",
    "    gdf['q_S3_Ls'] = (gdf['p_rural'] * gdf['Rural_Rate_Ls'] + \n",
    "                      (1 - gdf['p_rural']) * gdf['Urban_Rate_Ls'])\n",
    "    \n",
    "    gdf['Q_S3_Ls'] = gdf['Discrepancy'] * gdf['q_S3_Ls']\n",
    "    gdf['Q_S3_m3_day'] = gdf['Q_S3_Ls'] * SECONDS_PER_DAY * LITERS_TO_M3\n",
    "    gdf['Q_S3_m3_year'] = gdf['Q_S3_Ls'] * SECONDS_PER_YEAR * LITERS_TO_M3\n",
    "    \n",
    "    total_Q_S3_Ls = gdf['Q_S3_Ls'].sum()\n",
    "    total_Q_S3_m3_year = gdf['Q_S3_m3_year'].sum()\n",
    "    \n",
    "    print(f\"   Parameters: p_productive = {P_PRODUCTIVE:.0%}, q_productive = {Q_PRODUCTIVE_LS} L/s\")\n",
    "    print(f\"   Total unregistered extraction (S3):\")\n",
    "    print(f\"      - {total_Q_S3_Ls:,.2f} L/s\")\n",
    "    print(f\"      - {total_Q_S3_m3_year:,.0f} m³/year\")\n",
    "    print(f\"      - {total_Q_S3_m3_year/1e6:,.2f} million m³/year\")\n",
    "    print(f\"   Increase over S1: {((total_Q_S3_m3_year/total_Q_S1_m3_year)-1)*100:+.1f}%\")\n",
    "    print(f\"   Increase over S2: {((total_Q_S3_m3_year/total_Q_S2_m3_year)-1)*100:+.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 10: Calculating total extraction (DGA + Unregistered)...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    if 'DGA_Caudal_Ls' in gdf.columns:\n",
    "        gdf['Q_DGA_Ls'] = gdf['DGA_Caudal_Ls']\n",
    "        gdf['Q_DGA_m3_year'] = gdf['DGA_Caudal_Ls'] * SECONDS_PER_YEAR * LITERS_TO_M3\n",
    "    else:\n",
    "        gdf['Q_DGA_Ls'] = 0\n",
    "        gdf['Q_DGA_m3_year'] = 0\n",
    "    \n",
    "    gdf['Q_Total_S1_Ls'] = gdf['Q_DGA_Ls'] + gdf['Q_S1_Ls']\n",
    "    gdf['Q_Total_S2_Ls'] = gdf['Q_DGA_Ls'] + gdf['Q_S2_Ls']\n",
    "    gdf['Q_Total_S3_Ls'] = gdf['Q_DGA_Ls'] + gdf['Q_S3_Ls']\n",
    "    \n",
    "    gdf['Q_Total_S1_m3y'] = gdf['Q_DGA_m3_year'] + gdf['Q_S1_m3_year']\n",
    "    gdf['Q_Total_S2_m3y'] = gdf['Q_DGA_m3_year'] + gdf['Q_S2_m3_year']\n",
    "    gdf['Q_Total_S3_m3y'] = gdf['Q_DGA_m3_year'] + gdf['Q_S3_m3_year']\n",
    "    \n",
    "    gdf['Pct_Unreg_S1'] = np.where(\n",
    "        gdf['Q_Total_S1_m3y'] > 0,\n",
    "        (gdf['Q_S1_m3_year'] / gdf['Q_Total_S1_m3y']) * 100,\n",
    "        0\n",
    "    )\n",
    "    gdf['Pct_Unreg_S2'] = np.where(\n",
    "        gdf['Q_Total_S2_m3y'] > 0,\n",
    "        (gdf['Q_S2_m3_year'] / gdf['Q_Total_S2_m3y']) * 100,\n",
    "        0\n",
    "    )\n",
    "    gdf['Pct_Unreg_S3'] = np.where(\n",
    "        gdf['Q_Total_S3_m3y'] > 0,\n",
    "        (gdf['Q_S3_m3_year'] / gdf['Q_Total_S3_m3y']) * 100,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    Q_DGA_national = gdf['Q_DGA_m3_year'].sum()\n",
    "    Q_Total_S1 = gdf['Q_Total_S1_m3y'].sum()\n",
    "    Q_Total_S2 = gdf['Q_Total_S2_m3y'].sum()\n",
    "    Q_Total_S3 = gdf['Q_Total_S3_m3y'].sum()\n",
    "    \n",
    "    print(f\"\\n   === INTEGRATED NATIONAL EXTRACTION ===\")\n",
    "    print(f\"   {'Source':<35} {'Flow (L/s)':>15} {'Volume (Mm³/yr)':>18}\")\n",
    "    print(f\"   {'-'*70}\")\n",
    "    print(f\"   {'DGA Registered':<35} {gdf['Q_DGA_Ls'].sum():>15,.2f} {Q_DGA_national/1e6:>18,.2f}\")\n",
    "    print(f\"   {'Unregistered (Scenario 1)':<35} {total_Q_S1_Ls:>15,.2f} {total_Q_S1_m3_year/1e6:>18,.2f}\")\n",
    "    print(f\"   {'Unregistered (Scenario 2)':<35} {total_Q_S2_Ls:>15,.2f} {total_Q_S2_m3_year/1e6:>18,.2f}\")\n",
    "    print(f\"   {'Unregistered (Scenario 3)':<35} {total_Q_S3_Ls:>15,.2f} {total_Q_S3_m3_year/1e6:>18,.2f}\")\n",
    "    print(f\"   {'-'*70}\")\n",
    "    print(f\"   {'TOTAL (DGA + S1)':<35} {gdf['Q_Total_S1_Ls'].sum():>15,.2f} {Q_Total_S1/1e6:>18,.2f}\")\n",
    "    print(f\"   {'TOTAL (DGA + S2)':<35} {gdf['Q_Total_S2_Ls'].sum():>15,.2f} {Q_Total_S2/1e6:>18,.2f}\")\n",
    "    print(f\"   {'TOTAL (DGA + S3)':<35} {gdf['Q_Total_S3_Ls'].sum():>15,.2f} {Q_Total_S3/1e6:>18,.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 11: Preparing output columns...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    new_cols = [\n",
    "        'Discrepancy', 'Ratio_Census_DGA',\n",
    "        'H_Block', 'Used_Default_H',\n",
    "        'p_exclusive', 'Pozos_Exclusivos', 'p_rural',\n",
    "        'q_dom_Ls', 'Q_S1_Ls', 'Q_S1_m3_day', 'Q_S1_m3_year',\n",
    "        'q_enhanced_Ls', 'q_S2_Ls', 'Q_S2_Ls', 'Q_S2_m3_day', 'Q_S2_m3_year',\n",
    "        'Rural_Rate_Ls', 'Urban_Rate_Ls', 'q_S3_Ls', 'Q_S3_Ls', 'Q_S3_m3_day', 'Q_S3_m3_year',\n",
    "        'Q_DGA_Ls', 'Q_DGA_m3_year',\n",
    "        'Q_Total_S1_Ls', 'Q_Total_S2_Ls', 'Q_Total_S3_Ls',\n",
    "        'Q_Total_S1_m3y', 'Q_Total_S2_m3y', 'Q_Total_S3_m3y',\n",
    "        'Pct_Unreg_S1', 'Pct_Unreg_S2', 'Pct_Unreg_S3'\n",
    "    ]\n",
    "    \n",
    "    print(f\"   New columns added: {len(new_cols)}\")\n",
    "    print(f\"   Total columns: {len(gdf.columns)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 12: Saving shapefile...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    new_col_shp_map = {\n",
    "        'Discrepancy': 'Discrep',\n",
    "        'Ratio_Census_DGA': 'Ratio_C_D',\n",
    "        'H_Block': 'H_Block',\n",
    "        'Used_Default_H': 'Used_Def_H',\n",
    "        'p_exclusive': 'p_exclus',\n",
    "        'Pozos_Exclusivos': 'Pozos_Exc',\n",
    "        'p_rural': 'p_rural',\n",
    "        'q_dom_Ls': 'q_dom_Ls',\n",
    "        'Q_S1_Ls': 'Q_S1_Ls',\n",
    "        'Q_S1_m3_day': 'Q_S1_m3d',\n",
    "        'Q_S1_m3_year': 'Q_S1_m3y',\n",
    "        'q_enhanced_Ls': 'q_enh_Ls',\n",
    "        'q_S2_Ls': 'q_S2_Ls',\n",
    "        'Q_S2_Ls': 'Q_S2_Ls',\n",
    "        'Q_S2_m3_day': 'Q_S2_m3d',\n",
    "        'Q_S2_m3_year': 'Q_S2_m3y',\n",
    "        'Rural_Rate_Ls': 'Rur_Rate',\n",
    "        'Urban_Rate_Ls': 'Urb_Rate',\n",
    "        'q_S3_Ls': 'q_S3_Ls',\n",
    "        'Q_S3_Ls': 'Q_S3_Ls',\n",
    "        'Q_S3_m3_day': 'Q_S3_m3d',\n",
    "        'Q_S3_m3_year': 'Q_S3_m3y',\n",
    "        'Q_DGA_Ls': 'Q_DGA_Ls',\n",
    "        'Q_DGA_m3_year': 'Q_DGA_m3y',\n",
    "        'Q_Total_S1_Ls': 'QTot_S1Ls',\n",
    "        'Q_Total_S2_Ls': 'QTot_S2Ls',\n",
    "        'Q_Total_S3_Ls': 'QTot_S3Ls',\n",
    "        'Q_Total_S1_m3y': 'QTot_S1m3',\n",
    "        'Q_Total_S2_m3y': 'QTot_S2m3',\n",
    "        'Q_Total_S3_m3y': 'QTot_S3m3',\n",
    "        'Pct_Unreg_S1': 'Pct_Un_S1',\n",
    "        'Pct_Unreg_S2': 'Pct_Un_S2',\n",
    "        'Pct_Unreg_S3': 'Pct_Un_S3'\n",
    "    }\n",
    "    \n",
    "    all_col_map = {**REVERSE_COL_MAP, **new_col_shp_map}\n",
    "    \n",
    "    gdf_shp = gdf.copy()\n",
    "    \n",
    "    rename_dict = {}\n",
    "    for col in gdf_shp.columns:\n",
    "        if col == 'geometry':\n",
    "            continue\n",
    "        if col in all_col_map:\n",
    "            rename_dict[col] = all_col_map[col]\n",
    "        elif len(col) > 10:\n",
    "            rename_dict[col] = col[:10]\n",
    "    \n",
    "    gdf_shp = gdf_shp.rename(columns=rename_dict)\n",
    "    \n",
    "    shp_path = os.path.join(OUTPUT_FOLDER, 'Shapefiles', 'Census_DGA_WaterConsumption_Estimates.shp')\n",
    "    gdf_shp.to_file(shp_path, driver='ESRI Shapefile', encoding='utf-8')\n",
    "    print(f\"   ✅ Shapefile saved: {shp_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 13: Saving CSV...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    df_csv = gdf.drop(columns='geometry').copy()\n",
    "    \n",
    "    float_cols = df_csv.select_dtypes(include=[np.floating]).columns\n",
    "    for col in float_cols:\n",
    "        df_csv[col] = df_csv[col].round(4)\n",
    "    \n",
    "    csv_path = os.path.join(OUTPUT_FOLDER, 'CSV', 'Census_DGA_WaterConsumption_Estimates.csv')\n",
    "    df_csv.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"   ✅ CSV saved: {csv_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 14: Saving aggregated Excel files...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    def aggregate_results(df, group_col, name_col):\n",
    "        agg_dict = {\n",
    "            'Census_Wells': 'sum',\n",
    "            'DGA_WaterRights': 'sum',\n",
    "            'Discrepancy': 'sum',\n",
    "            'Personas_24': 'sum',\n",
    "            'Viviendas_24': 'sum',\n",
    "            'Is_Rural': 'sum',\n",
    "            'Q_S1_Ls': 'sum',\n",
    "            'Q_S1_m3_year': 'sum',\n",
    "            'Q_S2_Ls': 'sum',\n",
    "            'Q_S2_m3_year': 'sum',\n",
    "            'Q_S3_Ls': 'sum',\n",
    "            'Q_S3_m3_year': 'sum',\n",
    "            'Q_DGA_Ls': 'sum',\n",
    "            'Q_DGA_m3_year': 'sum',\n",
    "            'Q_Total_S1_Ls': 'sum',\n",
    "            'Q_Total_S1_m3y': 'sum',\n",
    "            'Q_Total_S2_Ls': 'sum',\n",
    "            'Q_Total_S2_m3y': 'sum',\n",
    "            'Q_Total_S3_Ls': 'sum',\n",
    "            'Q_Total_S3_m3y': 'sum'\n",
    "        }\n",
    "        \n",
    "        agg_dict = {k: v for k, v in agg_dict.items() if k in df.columns}\n",
    "        \n",
    "        agg = df.groupby(group_col, dropna=False).agg(agg_dict).reset_index()\n",
    "        agg = agg.rename(columns={group_col: name_col})\n",
    "        \n",
    "        block_counts = df.groupby(group_col, dropna=False).size().reset_index(name='N_Blocks')\n",
    "        block_counts = block_counts.rename(columns={group_col: name_col})\n",
    "        agg = agg.merge(block_counts, on=name_col, how='left')\n",
    "        \n",
    "        if 'Q_Total_S3_m3y' in agg.columns and 'Q_S3_m3_year' in agg.columns:\n",
    "            agg['Pct_Unregistered_S3'] = np.where(\n",
    "                agg['Q_Total_S3_m3y'] > 0,\n",
    "                (agg['Q_S3_m3_year'] / agg['Q_Total_S3_m3y']) * 100,\n",
    "                0\n",
    "            )\n",
    "        \n",
    "        return agg\n",
    "    \n",
    "    aggregation_levels = [\n",
    "        ('Region_Name', 'Region'),\n",
    "        ('Muni_Name', 'Municipality'),\n",
    "        ('Cuenca_Name', 'Basin'),\n",
    "        ('SHAC_Name', 'SHAC')\n",
    "    ]\n",
    "    \n",
    "    aggregated_results = {}\n",
    "    for group_col, name in aggregation_levels:\n",
    "        if group_col in gdf.columns:\n",
    "            agg_df = aggregate_results(gdf, group_col, name)\n",
    "            agg_df = agg_df.sort_values('Q_S3_m3_year', ascending=False)\n",
    "            aggregated_results[name] = agg_df\n",
    "            print(f\"   Aggregated at {name} level: {len(agg_df)} units\")\n",
    "    \n",
    "    national_summary = pd.DataFrame({\n",
    "        'Parameter': [\n",
    "            'Total Census Blocks',\n",
    "            'Total Census Wells',\n",
    "            'Total DGA Rights',\n",
    "            'Total Discrepancy (Unregistered)',\n",
    "            'Ratio Census/DGA',\n",
    "            'National avg H (persons/household)',\n",
    "            'p_exclusive (national)',\n",
    "            'p_rural (national)',\n",
    "            '',\n",
    "            '--- SCENARIO 1: UNIFORM DOMESTIC ---',\n",
    "            'Unregistered Q (S1) [L/s]',\n",
    "            'Unregistered Q (S1) [Mm³/year]',\n",
    "            '',\n",
    "            '--- SCENARIO 2: STRATIFIED ---',\n",
    "            'Unregistered Q (S2) [L/s]',\n",
    "            'Unregistered Q (S2) [Mm³/year]',\n",
    "            '',\n",
    "            '--- SCENARIO 3: MIXED-USE ---',\n",
    "            'Unregistered Q (S3) [L/s]',\n",
    "            'Unregistered Q (S3) [Mm³/year]',\n",
    "            '',\n",
    "            '--- TOTAL EXTRACTION ---',\n",
    "            'DGA Registered [L/s]',\n",
    "            'DGA Registered [Mm³/year]',\n",
    "            'Total (DGA+S1) [Mm³/year]',\n",
    "            'Total (DGA+S2) [Mm³/year]',\n",
    "            'Total (DGA+S3) [Mm³/year]',\n",
    "            '% Unregistered (S1)',\n",
    "            '% Unregistered (S2)',\n",
    "            '% Unregistered (S3)'\n",
    "        ],\n",
    "        'Value': [\n",
    "            len(gdf),\n",
    "            total_census,\n",
    "            total_dga,\n",
    "            total_discrepancy,\n",
    "            total_census / total_dga if total_dga > 0 else 0,\n",
    "            H_AVG_NATIONAL,\n",
    "            p_exclusive_national,\n",
    "            p_rural_national,\n",
    "            '',\n",
    "            '',\n",
    "            total_Q_S1_Ls,\n",
    "            total_Q_S1_m3_year / 1e6,\n",
    "            '',\n",
    "            '',\n",
    "            total_Q_S2_Ls,\n",
    "            total_Q_S2_m3_year / 1e6,\n",
    "            '',\n",
    "            '',\n",
    "            total_Q_S3_Ls,\n",
    "            total_Q_S3_m3_year / 1e6,\n",
    "            '',\n",
    "            '',\n",
    "            gdf['Q_DGA_Ls'].sum(),\n",
    "            Q_DGA_national / 1e6,\n",
    "            Q_Total_S1 / 1e6,\n",
    "            Q_Total_S2 / 1e6,\n",
    "            Q_Total_S3 / 1e6,\n",
    "            (total_Q_S1_m3_year / Q_Total_S1) * 100 if Q_Total_S1 > 0 else 0,\n",
    "            (total_Q_S2_m3_year / Q_Total_S2) * 100 if Q_Total_S2 > 0 else 0,\n",
    "            (total_Q_S3_m3_year / Q_Total_S3) * 100 if Q_Total_S3 > 0 else 0\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    params_df = pd.DataFrame({\n",
    "        'Parameter': [\n",
    "            'C_PC_DOMESTIC', 'C_PC_ENHANCED', 'H_AVG_DEFAULT', 'H_AVG_NATIONAL',\n",
    "            'P_PRODUCTIVE', 'Q_PRODUCTIVE_LS', 'p_exclusive_national', 'p_rural_national'\n",
    "        ],\n",
    "        'Value': [\n",
    "            C_PC_DOMESTIC, C_PC_ENHANCED, H_AVG_DEFAULT, H_AVG_NATIONAL,\n",
    "            P_PRODUCTIVE, Q_PRODUCTIVE_LS, p_exclusive_national, p_rural_national\n",
    "        ],\n",
    "        'Unit': [\n",
    "            'L/person/day', 'L/person/day', 'persons/household', 'persons/household',\n",
    "            'fraction', 'L/s', 'fraction', 'fraction'\n",
    "        ],\n",
    "        'Description': [\n",
    "            'Standard domestic consumption',\n",
    "            'Enhanced consumption (exclusive wells)',\n",
    "            'Default household size',\n",
    "            'National average household size',\n",
    "            'Fraction rural wells with productive use',\n",
    "            'Productive well extraction rate',\n",
    "            'Proportion exclusive well dependence',\n",
    "            'Proportion wells in rural areas'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    col_definitions = pd.DataFrame({\n",
    "        'Column': [\n",
    "            '--- DISCREPANCY ---',\n",
    "            'Discrepancy', 'Ratio_Census_DGA',\n",
    "            '',\n",
    "            '--- HOUSEHOLD SIZE ---',\n",
    "            'H_Block', 'Used_Default_H',\n",
    "            '',\n",
    "            '--- PROPORTIONS ---',\n",
    "            'p_exclusive', 'p_rural',\n",
    "            '',\n",
    "            '--- SCENARIO 1 (L/s) ---',\n",
    "            'q_dom_Ls', 'Q_S1_Ls',\n",
    "            '',\n",
    "            '--- SCENARIO 2 (L/s) ---',\n",
    "            'q_S2_Ls', 'Q_S2_Ls',\n",
    "            '',\n",
    "            '--- SCENARIO 3 (L/s) ---',\n",
    "            'q_S3_Ls', 'Q_S3_Ls',\n",
    "            '',\n",
    "            '--- ANNUAL VOLUME (m³/year) ---',\n",
    "            'Q_S1_m3_year', 'Q_S2_m3_year', 'Q_S3_m3_year',\n",
    "            '',\n",
    "            '--- TOTAL EXTRACTION ---',\n",
    "            'Q_Total_S1_m3y', 'Q_Total_S2_m3y', 'Q_Total_S3_m3y',\n",
    "            'Pct_Unreg_S1', 'Pct_Unreg_S2', 'Pct_Unreg_S3'\n",
    "        ],\n",
    "        'Description': [\n",
    "            '',\n",
    "            'Census Wells - DGA Rights (clipped to 0)',\n",
    "            'Census Wells / DGA Rights',\n",
    "            '',\n",
    "            '',\n",
    "            'Persons per household (block level)',\n",
    "            'Flag: 1 if using default H value',\n",
    "            '',\n",
    "            '',\n",
    "            'Proportion exclusive well dependence',\n",
    "            'Proportion in rural areas (Is_Rural)',\n",
    "            '',\n",
    "            '',\n",
    "            'Domestic rate per well [L/s]',\n",
    "            'Total unregistered extraction S1 [L/s]',\n",
    "            '',\n",
    "            '',\n",
    "            'Stratified rate per well [L/s]',\n",
    "            'Total unregistered extraction S2 [L/s]',\n",
    "            '',\n",
    "            '',\n",
    "            'Mixed-use rate per well [L/s]',\n",
    "            'Total unregistered extraction S3 [L/s]',\n",
    "            '',\n",
    "            '',\n",
    "            'Annual S1 volume', 'Annual S2 volume', 'Annual S3 volume',\n",
    "            '',\n",
    "            '',\n",
    "            'DGA + S1 annual volume', 'DGA + S2 annual volume', 'DGA + S3 annual volume',\n",
    "            'Percent unregistered S1', 'Percent unregistered S2', 'Percent unregistered S3'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    excel_path = os.path.join(OUTPUT_FOLDER, 'Excel', 'Water_Consumption_Estimates_All_Levels.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        national_summary.to_excel(writer, sheet_name='National_Summary', index=False)\n",
    "        params_df.to_excel(writer, sheet_name='Parameters', index=False)\n",
    "        col_definitions.to_excel(writer, sheet_name='Column_Definitions', index=False)\n",
    "        \n",
    "        df_csv.head(50000).to_excel(writer, sheet_name='Block_Level_Sample', index=False)\n",
    "        \n",
    "        for name, agg_df in aggregated_results.items():\n",
    "            sheet_name = f'{name}_Level'[:31]\n",
    "            agg_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    print(f\"   ✅ Excel saved: {excel_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 15: Generating report...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    report_lines = []\n",
    "    report_lines.append(\"=\"*100)\n",
    "    report_lines.append(\"GROUNDWATER EXTRACTION ESTIMATION REPORT\")\n",
    "    report_lines.append(\"From Census 2024 vs DGA Water Rights Comparison\")\n",
    "    report_lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    report_lines.append(\"\\nINPUT DATA:\")\n",
    "    report_lines.append(f\"  Source shapefile: {INPUT_SHAPEFILE}\")\n",
    "    report_lines.append(f\"  Census blocks analyzed: {len(gdf):,}\")\n",
    "    \n",
    "    report_lines.append(\"\\nPARAMETERS USED:\")\n",
    "    report_lines.append(f\"  C_PC_DOMESTIC: {C_PC_DOMESTIC} L/person/day\")\n",
    "    report_lines.append(f\"  C_PC_ENHANCED: {C_PC_ENHANCED} L/person/day\")\n",
    "    report_lines.append(f\"  H_AVG_DEFAULT: {H_AVG_DEFAULT} persons/household\")\n",
    "    report_lines.append(f\"  H_AVG_NATIONAL: {H_AVG_NATIONAL:.2f} persons/household\")\n",
    "    report_lines.append(f\"  P_PRODUCTIVE: {P_PRODUCTIVE:.0%}\")\n",
    "    report_lines.append(f\"  Q_PRODUCTIVE_LS: {Q_PRODUCTIVE_LS} L/s\")\n",
    "    report_lines.append(f\"  p_exclusive (national): {p_exclusive_national:.2%}\")\n",
    "    report_lines.append(f\"  p_rural (national): {p_rural_national:.2%}\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*80)\n",
    "    report_lines.append(\"NATIONAL SUMMARY\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(f\"Total Census Wells: {total_census:,.0f}\")\n",
    "    report_lines.append(f\"Total DGA Rights: {total_dga:,.0f}\")\n",
    "    report_lines.append(f\"Discrepancy (Unregistered): {total_discrepancy:,.0f}\")\n",
    "    report_lines.append(f\"Ratio Census/DGA: {total_census/total_dga:.2f}x\" if total_dga > 0 else \"Ratio: N/A\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- EXTRACTION ESTIMATES ---\")\n",
    "    report_lines.append(f\"{'Scenario':<25} {'Flow (L/s)':>15} {'Volume (Mm³/yr)':>18}\")\n",
    "    report_lines.append(\"-\"*60)\n",
    "    report_lines.append(f\"{'DGA Registered':<25} {gdf['Q_DGA_Ls'].sum():>15,.2f} {Q_DGA_national/1e6:>18,.2f}\")\n",
    "    report_lines.append(f\"{'S1: Uniform Domestic':<25} {total_Q_S1_Ls:>15,.2f} {total_Q_S1_m3_year/1e6:>18,.2f}\")\n",
    "    report_lines.append(f\"{'S2: Stratified':<25} {total_Q_S2_Ls:>15,.2f} {total_Q_S2_m3_year/1e6:>18,.2f}\")\n",
    "    report_lines.append(f\"{'S3: Mixed-Use':<25} {total_Q_S3_Ls:>15,.2f} {total_Q_S3_m3_year/1e6:>18,.2f}\")\n",
    "    report_lines.append(\"-\"*60)\n",
    "    report_lines.append(f\"{'TOTAL (DGA + S3)':<25} {gdf['Q_Total_S3_Ls'].sum():>15,.2f} {Q_Total_S3/1e6:>18,.2f}\")\n",
    "    \n",
    "    report_lines.append(\"\\n--- KEY FINDINGS ---\")\n",
    "    report_lines.append(f\"• Unregistered wells add {(total_Q_S1_m3_year/Q_DGA_national)*100:.0f}% - {(total_Q_S3_m3_year/Q_DGA_national)*100:.0f}% to registered extraction\" if Q_DGA_national > 0 else \"\")\n",
    "    report_lines.append(f\"• {p_exclusive_national*100:.1f}% of well users have NO public network access\")\n",
    "    report_lines.append(f\"• {p_rural_national*100:.1f}% of all wells are in RURAL areas\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*80)\n",
    "    report_lines.append(\"OUTPUT FILES\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(f\"Shapefile: {shp_path}\")\n",
    "    report_lines.append(f\"CSV: {csv_path}\")\n",
    "    report_lines.append(f\"Excel: {excel_path}\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*80)\n",
    "    report_lines.append(\"SHAPEFILE COLUMNS (NEW)\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(\"Discrep: Discrepancy (Census - DGA, clipped to 0)\")\n",
    "    report_lines.append(\"H_Block: Household size per block\")\n",
    "    report_lines.append(\"p_exclus: Exclusive well dependence proportion\")\n",
    "    report_lines.append(\"p_rural: Rural proportion (Is_Rural)\")\n",
    "    report_lines.append(\"Q_S1_Ls, Q_S1_m3y: Scenario 1 extraction (L/s, m³/year)\")\n",
    "    report_lines.append(\"Q_S2_Ls, Q_S2_m3y: Scenario 2 extraction (L/s, m³/year)\")\n",
    "    report_lines.append(\"Q_S3_Ls, Q_S3_m3y: Scenario 3 extraction (L/s, m³/year)\")\n",
    "    report_lines.append(\"QTot_S*: Total extraction (DGA + Scenario)\")\n",
    "    report_lines.append(\"Pct_Un_S*: Percentage unregistered\")\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\"*100)\n",
    "    report_lines.append(\"END OF REPORT\")\n",
    "    report_lines.append(\"=\"*100)\n",
    "    \n",
    "    report_path = os.path.join(OUTPUT_FOLDER, 'Reports', \n",
    "                              f'Water_Consumption_Report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(report_lines))\n",
    "    print(f\"   ✅ Report saved: {report_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nOutput folder: {OUTPUT_FOLDER}\")\n",
    "    print(f\"\\nFiles generated:\")\n",
    "    print(f\"  - Shapefile: Shapefiles/Census_DGA_WaterConsumption_Estimates.shp\")\n",
    "    print(f\"  - CSV: CSV/Census_DGA_WaterConsumption_Estimates.csv\")\n",
    "    print(f\"  - Excel: Excel/Water_Consumption_Estimates_All_Levels.xlsx\")\n",
    "    print(f\"  - Report: Reports/Water_Consumption_Report_*.txt\")\n",
    "    \n",
    "    print(f\"\\n--- KEY RESULTS ---\")\n",
    "    print(f\"Unregistered wells: {total_discrepancy:,.0f}\")\n",
    "    print(f\"Unregistered extraction (S1-S3): {total_Q_S1_m3_year/1e6:.1f} - {total_Q_S3_m3_year/1e6:.1f} Mm³/year\")\n",
    "    print(f\"Total extraction (DGA + S3): {Q_Total_S3/1e6:.1f} Mm³/year\")\n",
    "    \n",
    "    print(f\"\\nFinished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-water]",
   "language": "python",
   "name": "conda-env-.conda-water-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
